{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#127794; Digital Champion - Hands-On Python Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#128210; Inhaltsverzeichnis:\n",
    "* [1 Einf√ºhrung](#first-bullet)\n",
    "* [2 Entscheidungsb√§ume Theorie & Aufgabenstellung](#second-bullet)\n",
    "* [3 Datenaufbereitung](#third-bullet)\n",
    "* [4 Einfacher Entscheidungsbaum](#fourth-bullet)\n",
    "* [5 Optimierter Entscheidungsbaum](#fifth-bullet)\n",
    "* [6 Abschluss](#sixth-bullet)\n",
    "* [7 Anhang](#seventh-bullet)\n",
    "* [8 L√∂sungen](#eight-bullet)\n",
    "* [9 Quellen](#nineth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Einf√ºhrung (5 min) <a class=\"anchor\" name=\"first-bullet\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks sind interaktive Entwicklungsumgebungen, die es erm√∂glichen, Code, Visualisierungen und Text in einer einzigen Umgebung zu kombinieren. Sie werden h√§ufig f√ºr die Datenanalyse, den Code-Austausch und die Dokumentation verwendet. Mit Jupyter Notebooks k√∂nnen Python-Codezellen ausgef√ºhrt und die Ergebnisse sofort angezeigt werden. In diesem Jupyter-Notebook werden wir ```Entscheidungsb√§ume``` betrachten.\n",
    "\n",
    "![alt text for screen readers](./pictures/jupyter_intro_google.png \"Einf√ºhrung Jupyter Notebook\").\n",
    "\n",
    "### Erkl√§rungen:\n",
    "* &#10133; **Code:** Mit diesem Symbol k√∂nnen wir eine neue Code-Zelle in das Notebook einf√ºgen. Die Code-Zellen werden dazu verwendet, um ausf√ºhrbaren Code einzugeben. In einer Code-Zelle k√∂nnen Programmiersprachen wie Python, R, Julia und andere verwendet werden.\n",
    "* &#10133; **Text:** Mit diesem Symbol k√∂nnen wir eine neue Text-Zelle in das Notebook einf√ºgen. Die Text-Zellen dienen zur Eingabe und Formatierung von Text. Sie erm√∂glichen es, Text, √úberschriften, Aufz√§hlungen, Bilder und andere Formatierungselemente einzuf√ºgen.\n",
    "* üóëÔ∏è **L√∂schen:** Mit diesem Symbol k√∂nnen wir eine Zelle l√∂schen und deren Inhalt entfernen.\n",
    "* &#9654; **Ausf√ºhren:** Mit diesem Symbol k√∂nnen wir den Code in einer Zelle ausf√ºhren.\n",
    "* ```Laufzeit``` -> ```Alle ausf√ºhren``` Der Kernel f√ºhrt den Code aus und gibt die Ergebnisse zur√ºck an das Notebook. Es kann sein, dass der Kernel nicht mehr verbunden ist. In diesem Fall m√ºssen wir den Kernel neustarten und alle Zellen neu laufen lassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wichtig: Diese beiden Zeilen m√ºssen zwingend ausgef√ºhrt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L√§dt unseren Datensatz aus dem LearningFriday GitHub Repository herunter\n",
    "!git clone https://github.com/LearningFridayPost/dc-jupyter-notebook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Ñndert working directory, sodass Daten korrekt eingelesen werden k√∂nnen\n",
    "%cd dc-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "- Wir lesen das Notebook durch und bearbeiten die Aufgaben direkt in diesem Notebook\n",
    "    \n",
    "- Die L√∂sungen k√∂nnen wir mit dem Link unter den Aufgaben aufrufen\n",
    "    \n",
    "- Fragen bitte direkt in den Chat schreiben\n",
    "\n",
    "- Komplexere Fragen werden in Breakout-Sessions behandelt\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Entscheidungsb√§ume: Theorie & Aufgabenstellung (8 min) <a class=\"anchor\" name=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Was ist ein Entscheidungsbaum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidungsb√§ume sind eine Methode zur automatischen Klassifizierung von Datenobjekten (z.B. Personen oder Objekte) und damit zur L√∂sung von Entscheidungsproblemen. Ein Entscheidungsbaum besteht immer aus einem Wurzelknoten (root node) und beliebig vielen inneren Knoten (split node) sowie mindestens zwei Bl√§ttern (leaf node). Dabei repr√§sentiert jeder Knoten eine logische Regel und jedes Blatt eine Antwort auf das Entscheidungsproblem. Im Folgenden ist ein Beispiel f√ºr einen Entscheidungsbaum abgebildet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/dt-example-new.png \"Beispiel Entscheidungsbaum\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben einen Datensatz mit vielen Personen. F√ºr jede Person haben wir das Einkommen und die Information, ob eine Person eine Hypothek hat. Das Ziel ist es, herauszufinden, ob eine bestimmte Persone eine Versicherung hat (Klasse: ```Has Insurance```) oder nicht (Klasse: ```No Insurance```). Das heisst konkret: Mit dem abgebildeten Entscheidungsbaum wollen wir mit den Informationen von ```income_usd``` und ```with_mortage``` herausfinden, ob eine Person eine Versicherung hat.\n",
    "\n",
    "Die folgenden Informationen sind im Entscheidungsbaum (Abbildung oben) enthalten:\n",
    "* **gini:** Der Gini-Index beschreibt, wie gut ein Knoten verschiedene Klassen (z.B. ```No Insurance```, ```Has Insurance```) separiert. Der Wert ist immer zwischen 0 und 1. Je kleiner der Gini-Index ist, desto besser. Bei der Konstruktion des Entscheidungsbaumes wird bei jedem Knoten der Gini-Index berechnet. Es wird immer die logische Regel gew√§hlt, welche den besten Gini-Index aufweist.\n",
    "* **samples:** Dieser Wert beschreibt die Anzahl Beobachtungen (z.B. Daten von Personen), welche f√ºr den Split eines spezifischen Knotens zur Verf√ºgung stehen. Wir sehen beispielsweise, dass f√ºr die Konstruktion dieses Baumes Daten von 24 Personen verwendet wurden. Weiter sehen wir, dass der erste Knoten die 24 Personen in eine Gruppe mit 13 und eine Gruppe mit 11 Personen aufteilt.\n",
    "* **value:** Value beschreibt, wie die Aufteilung der ```samples``` im Knoten aussieht. Der Wert ```[15, 9]``` im ersten Knoten beschreibt beispielsweise, dass von 24 Personen, 15 keine Versicherung (Klasse: ```No Insurance```) und 9 Personen eine Versicherung (Klasse: ```Has Insurance```) haben.\n",
    "* **class:** Dieser Wert zeigt die Klasse, welche einem spezifischem Knoten zugewiesen wird. Beispiel: Im ersten Knoten sehen wir die Klasse ```No Insurance```, da von den 24 Personen mehr ```No Insurance``` (15) haben, als ```Has Insurance``` (9). Wir k√∂nnen die Klasse auch ahhand der Farben ablesen. Je r√∂ter ein Knoten ist, desto eher geh√∂rt er zur Klasse ```No Insurance``` und je blauer ein Knoten ist, desto eher geh√∂rt er zur Klasse ```Has Insurance```.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>\n",
    "Wie kann man einen Entscheidungsbaum lesen bzw. wie klassifizert der Entscheidungsbaum neue Beobachtungen (z.B. Personen):\n",
    "\n",
    "- Wir starten immer beim Wurzelknoten, d.h. ganz oben im Entscheidungsbaum.\n",
    "\n",
    "- Wenn die logische Regel im Knoten f√ºr die neue Beobachtung erf√ºllt ist, wird der linke Pfad im Entscheidungsbaum gew√§hlt. Wenn die logische Regel im Knoten nicht erf√ºllt ist, wird der rechte Pfad gew√§hlt.\n",
    "\n",
    "- Wir durchlaufen den Entscheidungsbaum so lange, bis wir bei einem Blatt ankommen. Das ```class``` Attribute im Blatt beschreibt die Klasse des neuen Datenobjekts.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_1'></a>\n",
    "&#9989; **AUFGABE 1:**</b> Bestimme die Klasse der beiden nachfolgeden Personen anhand des oben abgebildeten Entscheidungsbaums:\n",
    "\n",
    "- Person 1: income_usd = 100'000; with_mortage = 0\n",
    "\n",
    "- Person 2: income_usd = 73'000; with_mortage = 1\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 1](#l√∂sung_aufgabe_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung (mit # Kommentarfunktion):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Aufgabenstellung\n",
    "\n",
    "In diesem Jupyter-Notebook arbeiten wir mit dem ['heart-disease'](https://archive.ics.uci.edu/dataset/45/heart+disease) (HD) Datenset. Das Datenset ist eine Tabelle mit 14 Spalten (Features) und 303 Zeilen (Beobachtungen). Eine kurze Beschreibung der verschiedenen Features:\n",
    "* age: Alter\n",
    "* sex: Mann/Frau\n",
    "* restbp: resting blood pressure (Ruheblutdruck in mm/Hg bei Aufnahme ins Krankenhaus)\n",
    "* chol: Serumcholesterin in mg/dl\n",
    "* fbs: wenn der N√ºchternblutzucker > 120 mg/dl liegt\n",
    "* thalach: maximale Herzfrequenz erreicht\n",
    "* exang: Belastungsangina (Richtig/Falsch)\n",
    "* oldpeak: ST-Depression durch k√∂rperliche Bet√§tigung im Vergleich zur Ruhe\n",
    "* ca: Anzahl der gro√üen Gef√§√üe (0-3), gef√§rbt durch Fluoroskopie\n",
    "\n",
    "Unser Ziel ist es, mit den 303 Beobachtungen ein Modell zu generieren, welches neue Beobachtungen (bzw. Personen) klassifizieren und somit bestimmen kann, ob eine Herzerkrankung (HD) vorliegt oder nicht. Im Modell nutzen wir die oben beschriebenen Features um die Zielvariable (HD) vorherzusagen:\n",
    "* hd: Art der Herzerkrankung (hier: bin√§r)\n",
    "\n",
    "In einer Experten-Gruppe von Data Scientisten, haben wir besprochen, welches Modell wir verwenden m√∂chten. Wir haben uns entschieden, Entscheidungb√§ume zur Klassifikation von Herzerkrankungen zu benutzen, da diese einfach interpretierbar sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Datenaufbereitung (12 min) <a class=\"anchor\" name=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read data\n",
    "\n",
    "Bei jedem neuen Python-Projekt √ºberlegen wir uns, welche Python-Bibliotheken wir verwenden m√∂chten. Eine Python-Bibliothek ist ein wiederverwendbarer Codeblock, den wir in einem Programm bzw. Projekt einbinden k√∂nnen. Das Einbinden von solchen Codeblocks ist einiges schneller als den Code selber zu schreiben.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "Wenn wir in Python programmieren ist es wichtig, zu wissen, dass alles was hinter einem '#' steht kein Code ist, sondern nur ein Kommentar um den Code zu beschreiben. </div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "# pandas: Bibliothek zum Lesen und Bearbeiten von Daten\n",
    "import pandas as pd\n",
    "# numpy: Bibliothek zum Berechnen von KPIs\n",
    "import numpy as np\n",
    "# plt: Bibliothek zum Plotten von Grafiken\n",
    "import matplotlib.pyplot as plt\n",
    "# DecisionTreeClassifier: Modellierungskit f√ºr Entscheidungsb√§ume\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# plot_tree: Funktion zum Plotten von Entscheidungsb√§umen\n",
    "from sklearn.tree import plot_tree\n",
    "# train_test_split: Funktion, um Testobjekte in Training- bzw. Testset zu splitten\n",
    "from sklearn.model_selection import train_test_split\n",
    "# cross_val_score: Funktion zur Kreuzvalidierung\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# confusion_matrix: Funktion zum Berechnen der Wahrheitsmatrix (Konfusionsmatrix)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# ConfusionMatrixDispla: Funktion zum Plotten der Konfusionsmatrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# accuracy_score: Funktion zum Berechnen der Accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>   In Python werden Daten mit Hilft des '=' Operators in einer Variable gespeichert. Wenn wir beispielsweise die Zahl 5 in der Variable 'a' speichern m√∂chten, k√∂nnen wir das mit dem folgenden Code machen:\n",
    "<br><br>\n",
    "a = 5 \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(filepath_or_buffer, sep, encoding) erm√∂glicht es '.csv' Daten einzulesen\n",
    "# und in einer Variable als Tabelle zu speichern\n",
    "df = pd.read_csv(filepath_or_buffer='data/processed_cleveland_small.csv',\n",
    "                 sep=',',\n",
    "                 encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir die Variable 'df' aufrufen, wird sie angezeigt\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_2'></a>\n",
    "&#9989; **AUFGABE 2:**</b>\n",
    "Speichere die Daten in der Variable 'df_start'\n",
    "    \n",
    "-> L√∂sungen zu [Aufgabe 2](#l√∂sung_aufgabe_2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() zeigt, wie die ersten f√ºnf Zeilen in der Tabelle aussehen\n",
    "df_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fehlende Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir den Spaltennamen in eckige Klammer schreiben, z.B. df_start['Spaltenname'], erhalten wir die Werte dieser Spalte\n",
    "df_start['ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte angezeigte Wert ist ein '?'. Wir wollen kurz pr√ºfen, ob es noch mehr solche 'speziellen' Werte gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .unique() zeigt alle einzigartigen Elemente in der Spalte 'ca'\n",
    "df_start['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Wert '?' ist der einzige nicht-numerische Wert in der Spalte 'ca'. Bei solchen Werten m√ºssen wir vorsichtig sein. Es kann sich um einen Ausreisser oder einen fehlenden Wert handeln. Das Data Science Team nimmt deshalb Kontakt mit dem Autor des Datensatzes auf. Nach einigen Abkl√§rungen sind wir uns sicher, dass es fehlende Daten sind. Wir wissen jedoch noch nicht, wie oft solche fehlenden Daten vorkommen.\n",
    "\n",
    "Um zu sehen, wie oft dieser Wert vorkommt, filtern wir nach dem Wert '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Tabellenname['Spaltenname'] == 'zu pr√ºfender Text'] kann verwendet werden, um eine Tabelle nach einem spezifischen Spaltenwert zu filtern\n",
    "df_start[df_start['ca'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Wert '?' kommt nur sehr selten vor. Wir beschliessen, dises Beobachtungen aus dem Datensatz zu entfernen. Das heisst: Wir entfernen jede Beobachtung mit einem Fragezeichen. \n",
    "\n",
    "Grund: Fehlende Daten k√∂nnen zu Fehlern in der Konstruktion von Entscheidungsb√§umen f√ºhren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>  Die wichtigsten Vergleichsoperatoren:\n",
    "    \n",
    "* ```==```: zu vergleichendes Element muss den gleichen Inhalt haben\n",
    "* ```!=```: zu vergleichendes Element darf nicht den gleichen Inhalt haben\n",
    "* ```>=```: zu vergleichende Zahl muss gleich oder gr√∂sser sein\n",
    "* ```<=```: zu vergleichende Zahl muss gleich oder kleiner sein\n",
    "     \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_3'></a>\n",
    "&#9989; **AUFGABE 3:**</b>\n",
    "Wir haben gesehen, dass nur 4 Testobjekte in der Spalte 'ca' ein '?' enthalten. Da die Abkl√§rungen ergeben haben, dass es fehlende Daten sind, und dieses Ph√§nomen nur sehr wenige Testobjekte betrifft, wollen wir diese Werte aus unserer 'df_start' Tabelle rausfiltern und die neue Tabelle unter 'df_no_missing' speichern.\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 3](#l√∂sung_aufgabe_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Mit diesem Code pr√ºfen wir, ob alle '?' entfernt worden sind.\n",
    "df_no_missing['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ausreisser\n",
    "\n",
    "Die Autoren des Datensatzes haben uns bei dem Austausch gesagt, dass es zu unerkl√§rbaren Werten beim Alter gekommen ist. Das heisst: bei dem folgenden Feature vermuten wir Ausreisser (Outliers):\n",
    "* age: Alter der Testobjekte\n",
    "\n",
    "Eine weitverbreitete M√∂glichkeit, um die Daten auf Ausreisser zu pr√ºfen, ist mithilfe von Visualisierungen wie etwa den Boxplots. Ein Boxplot ist eine grafische Darstellung statistischer Verteilungen, die den Median, Quartile und Ausreisser visualisiert, indem es die Daten in Boxen darstellt.\n",
    "\n",
    "![alt text for screen readers](./pictures/boxplot-new.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .boxplot(Spaltenname) zeigt einen Boxplot f√ºr ein bestimmtes Feature\n",
    "df_no_missing.boxplot('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass es im Feature ```age``` keine Ausreisser hat. Die Autoren des Datensatzes scheinen die Daten schon bereinigt zu haben. Falls Ausreisser vorkommen, sollte man diese entfernen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Daten formatieren\n",
    "Im n√§chsten Schritt erfolgt die Aufteilung der Daten in Features und die Zielvariable. Alle Merkmale werden in die Tabelle ```X``` aufgenommen, w√§hrend die Werte der Zielvariable in der Tabelle ```y``` abgebildet werden.\n",
    "\n",
    "Hierbei repr√§sentiert ```X``` potenzielle Beobachtungen, also Daten von Personen, und ```y``` steht f√ºr die m√∂glichen Klassifizierungen (```0```=```keine Herzkrankheit```; ```1```=```hat Herzkrankheit```). Das √ºbergeordnete Ziel besteht darin, einen Entscheidungsbaum zu erstellen, der ```y``` m√∂glichst genau in Abh√§ngigkeit von ```X``` klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit der Funktion .copy() erstellen wir eine Kopie der Tabelle\n",
    "df_clean = df_no_missing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Features sollen in der Tabelle 'X' gespeichert werden\n",
    "# Die Funktion .drop('Spaltenname', axis=1) wird verwendet, um eine Spalte zu entfernen\n",
    "# Mit der Funktion .copy() erstellen wir eine Kopie der Tabelle\n",
    "X = df_clean.drop('hd', axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In diesem Schritt speichern wir die Zielvariable als 'y'\n",
    "y = df_clean['hd'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im n√§chsten Schritt erfolgt die Aufteilung unserer Daten in ein ```Trainingsset``` und ein ```Testset```:\n",
    "\n",
    "- ```Trainingsset```: Hierbei handelt es sich um Daten, die verwendet werden, um einen Entscheidungsbaum zu konstruieren und ihn anhand spezifischer Beobachtungen zu trainieren. Das Ziel ist es, dem Baum die charakteristischen Eigenschaften eines Datensatzes beizubringen.\n",
    "- ```Testset```: Dieses Datenset wird genutzt, um den Entscheidungsbaum zu testen. Es erm√∂glicht die √úberpr√ºfung, wie gut der Baum in der Lage ist, neue Beobachtungen zu klassifizieren und somit seine Leistungsf√§higkeit zu bewerten.\n",
    "\n",
    "![alt text for screen readers](./pictures/train_test_split.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion train_test_split(X, y) teilt die Daten in ein Trainings- und in ein Testset\n",
    "# Standardm√§ssig sind im Testset 25% der Daten vorhanden und im Trainingsset 75%\n",
    "# Wir sehen, dass train_test_split() 4 Tabellen generiert (je eine X und y Tabelle f√ºr beide Sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Einfacher Entscheidungsbaum (10 min) <a class=\"anchor\" name=\"fourth-bullet\"></a>\n",
    "### 4.1 Einfacher Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt konstruieren wir einen ```einfachen Entscheidungsbaum``` (ohne Optimierungen) abh√§ngig von unseren Beobachtungen im Trainingsset. Dieser Entscheidungsbaum erlaubt eine erste Klassifizierung von Objekten (z.B. Personen) hinsichtlich einer Herzkrankheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion DecisionTressClassifier() wird f√ºr die Konstruktion eines Entscheidungsbaumes verwendet\n",
    "clf_dt_e = DecisionTreeClassifier(random_state=42)\n",
    "# .fit(X_train, y_train) weist dem Entscheidungsbaum ein Trainingsset (X und y) zu\n",
    "clf_dt_e.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualisierung: Mit dem folgenden Code k√∂nnen wir einen Entscheidungsbaum visualisieren/plotten\n",
    "# Hier wird die Gr√∂sse des Plots definiert (15 steht f√ºr die Breite und 7.5 steht f√ºr die H√∂he)\n",
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# Die Funktion plot_tree(decision_tree, class_names, feature_names) wird f√ºr die Visualisieren eines Entscheidungsbaumes verwendet\n",
    "# 'decision_tree' steht f√ºr den Entscheidungsbaum der visualisiert werden soll\n",
    "plot_tree(decision_tree=clf_dt_e,\n",
    "          # 'filled=True' f√ºhrt dazu, dass die Knoten mit Farben gef√ºllt werden\n",
    "          filled=True,\n",
    "          # 'class_names=[\"kein HD\", \"hat HD\"]' gibt die Klassen an, die in jedem Knoten unter 'class' stehen sollen\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          # 'feature_names=X.columns' muss mitgegeben werden, damit die Features im Plot korrekt bezeichnet werden\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herlzichen Gl√ºckwunsch! Wir haben unseren ersten einfachen Entscheidungsbaum konstruiert. Jetzt wollen wir sehen, wie gut dieser Entscheidungsbaum, welchen wir mit den Trainingsset trainiert haben, Klassifizierungen im Testset vornehmen kann. Das bedeutet, wir wollen sehen, wie neue Personen klassifiziert werden, welche nicht f√ºr das Training ben√∂tigt worden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .predict(Tabellenname) wird verwendet, um die Klassifizierungen durchzuf√ºhren\n",
    "# Als Input muss dieser Funktion ein Tabellenname mitgegeben werden -> die Tabelle muss die Test-Features enthalten\n",
    "predictions = clf_dt_e.predict(X_test)\n",
    "# Der Output ist eine Liste mit den Klassifizierungen (0=keine HD; 1=hat HD)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem n√§chsten Schritt wollen wir pr√ºfen, ob diese Klassifizierungen richtig oder falsch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion confusion_matrix(y_true, y_pred, labels) bietet eine M√∂glichkeit zur Pr√ºfung der Klassifizierung\n",
    "# 'y_true' -> Liste der korrekten Klassifizierungen\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      # 'y_pred' -> Liste der vogenommenen Klassifizierungen\n",
    "                      y_pred=predictions,\n",
    "                      # 'labels' -> Klassen von clf_dt mitgeben\n",
    "                      labels=clf_dt_e.classes_)\n",
    "\n",
    "# Die Funktion ConfusionMatrixDisplay(confusion_matrix, display_labels) dient zur Visualisierung der Confusion-Matrix 'cm'\n",
    "# 'confusion_matrix' -> Confusion-Matrix die visualisiert werden soll\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              # 'display_labels' -> welche Labels sollen auf der Visualisierung dargestellt werden\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "# Die Funktion .plot() erstellt die Visualisierung\n",
    "disp.plot()\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die oben abgebildete Grafik zeigt eine ```Confusion-Matrix```. Sie wird wie folgt gelesen:\n",
    "- 31: Haben keine Herzkrankheit -> Diese 31 haben wir korrekt klassifiziert (True Negative TN) <br>\n",
    "- 12: Haben keine Herzkrankheit -> Diese 12 haben wir falsch klassifiziert (False Negative FN) <br>\n",
    "- 25: Haben eine Herzkrankheit -> Diese 25 haben wir korrekt klassifiziert (True Positive TP) <br>\n",
    "- 7: Haben eine Herzkrankheit -> Diese 7 haben wir falsch klassifiziert (False Positive FP)\n",
    "\n",
    "Wie gut ein Entscheidungsbaum ist, definieren wir anhand der ```Accuracy```, welche mit Hilfe der ```Confusion-Matrix``` berechnet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "<br>\n",
    "<br>... bei unserem einfachen Entscheidungsbaum haben wir z.B. folgende accuracy:\n",
    "<br> \n",
    "<br>Accuracy = (25 + 31) / (25 + 31 + 7 + 12) = 0.75\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion accuracy_score(y_true, y_pred) zeigt die berechnete Accuracy\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Optimierter Entscheidungsbaum (10 min) <a class=\"anchor\" name=\"fifth-bullet\"></a>\n",
    "### 5.1 Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/ccp.png \"Pruning\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bisher einen ```einfachen Entscheidungsbaum``` konstruiert. Zusammen mit dem Data Science Team besprechen wir, ob dieser Entscheidungsbaum ausreichend ist. Jemand aus dem Team hat einen Zweifel: der Entscheidungsbaum k√∂nnte auf die Trainigsset √ºberangepasst (overfitting) sein. √úberanpassung/Overfitting ist ein bekanntes Ph√§nomen. Es bedeutet, dass die Klassifizierung von Beobachtungen aus unserem Trainigsset sehr gut funktioniert, aber weniger gut f√ºr die Klassifizierung von neuen Beobachtungen. Der Entscheidungsbaum ist also zu sehr an die Trainingsdaten angepasst (√ºberangepasst).\n",
    "\n",
    "Dieses Problem k√∂nnen wir l√∂sen, indem wir die Konstruktion des Entscheidungsbaumes vereinfachen. Dazu verwenden wir verschiedene Parameter (z. B. ```max_ Depth``` oder ```min_samples```) um den Entscheidungsbaum zu optimieren. Das f√ºhrt dazu, dass der Entscheidungsbaum weniger Bl√§tter hat und dadruch einfacher und weniger an die Trainingsdaten angepasst ist. Diesen Prozess nennt man ```Pruning```. Das Ziel ist es, mithilfe des ```Pruning``` die ```Accuracy``` f√ºr neue Beobachtungen zu verbessern.\n",
    "\n",
    "```Cost Complexity Pruning``` ist eine spezifische Methode, um einen kleineren Entscheidungsbaum zu finden, der bessere Ergebnisse bei neuen Beobachtungen liefert. Wir schauen, ob kleinere Teil-Entscheidungsb√§ume (Baum mit 38 Bl√§ttern, Baum mit 37 Bl√§ttern, etc.) bessere Ergebnisse liefern als gr√∂ssere. Damit kleinere B√§ume mit gr√∂sseren B√§umen verglichen werden k√∂nnen, verwenden wir den Parameter ```alpha``` als ein Strafterm/Penalty, der das Ergebnis von kleineren B√§umen verbessert (√úberanpassung vs. Genauigkeit im Testdatenset).\n",
    "\n",
    "Eine genauere Anleitung zum ```Cross Complexity Pruning``` findet ihr [hier](#anhang_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "Die Werte von ```alpha``` sind wie folgt zu interpretieren:\n",
    "- ``` 0```: Der Entscheidungsbaum ist nicht geprunt. Er hat die maximale Gr√∂sse und entspricht dem in Kapitel 4 konstruierten einfachen Entscheidungsbaum.\n",
    "- ```>0```: Je gr√∂sser ```alpha``` desto einfacher ist der Entscheidungsbaum. Das heisst, der Entscheidungsbaum wir mit steigendem ```alpha``` weniger Bl√§tter haben.\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .cost_complexity_pruning_path(X_train, y_train) ist ein Algorithmus um m√∂glichst optimale Werte f√ºr alpha zu finden.\n",
    "path = clf_dt_e.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir w√§hlen einen Wert aus der Liste und konstruieren einen Entscheidungsbaum mit 'alpha' = 0.0077381\n",
    "value_alpha = 0.0077381\n",
    "\n",
    "# Definition des Entscheidungsbaums\n",
    "clf_dt_new = DecisionTreeClassifier(random_state=42,\n",
    "                                    ccp_alpha=value_alpha)\n",
    "clf_dt_new.fit(X_train, y_train)\n",
    "\n",
    "# Visualisierung des Entscheidungsbaums\n",
    "plot_tree(decision_tree=clf_dt_new,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_4'></a>\n",
    "&#9989; **AUFGABE 4:**</b>\n",
    "\n",
    "Konstruiere und plotte drei verschiedene Entscheidungsb√§ume mit verschiedenen 'alpha' Values. F√ºr die Konstruktion kannst du den obigen Code verwenden bzw. kopieren.\n",
    "    \n",
    "Bitte stelle sicher, dass du die Entscheidungsb√§ume in den folgenden Variablen abspeicherst:\n",
    "- clf_dt_1\n",
    "- clf_dt_2\n",
    "- clf_dt_3\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 4](#l√∂sung_aufgabe_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f√ºr den konstruierten Entscheidungsbaum 'clf_dt_new' wollen wir die Confusion-Matrix plotten, um zu sehen, wie gut er performt\n",
    "# Klasifizierungen\n",
    "predictions = clf_dt_new.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_new.classes_)\n",
    "\n",
    "# plotten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "\n",
    "# .plot() plottet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_5'></a>\n",
    "&#9989; **AUFGABE 5:**</b>\n",
    "\n",
    "Plotte die Confusion-Matrix f√ºr die in Aufgabe 4 kosnstruierten Entscheidungsb√§ume. F√ºr die Plots kannst du den obigen Code verwenden bzw. kopieren.\n",
    "<br>\n",
    "<br>-> L√∂sungen zu [Aufgabe 5](#l√∂sung_aufgabe_5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben gesehen, dass je nach ```alpha``` die Ergebnisse schlechter oder besser werden. Die Frage ist, wie wir auf eine einfache Art dasjenige 'alpha' finden, bei welchem die Ergebnisse am besten sind.\n",
    "\n",
    "Wir schreiben einen Code der Folgendes f√ºr uns erledigt:\n",
    "1. Einen Entscheidungsbaum pro ```alpha``` Wert konstruieren\n",
    "2. Pro Entscheidungsbaum die ```Accuracy``` f√ºr das Testset und das Trainingsset berechnen\n",
    "3. Die ```Accuracy``` f√ºr jeden Entscheidungsbaum in Abh√§ngigkeit von ```alpha``` plotten\n",
    "\n",
    "Den Code, welcher dies f√ºr uns ausf√ºhrt, findet ihr untenstehend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Komplexe Code-Zelle:</b> \n",
    "\n",
    "Die nachfolgende Code-Zelle muss nur ausgef√ºhrt werden. Das Nachvollziehen der Funktionsweise ist nicht Teil dieser Einf√ºhrung, dies w√ºrde √ºber den Scope hinaus gehen.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit [:-1] entfernen wir den gr√∂ssten 'alpha' Wert (das gr√∂sste 'alpha' hat keine Bl√§tter)\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "clf_dts = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    clf_dts.append(clf_dt)\n",
    "    \n",
    "# mit dem untenstehenden Code plotten wir 'Accuracy' in Abh√§ngigkeit zu 'alpha' (f√ºr Testdaten und Trainingsdaten)\n",
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im obigen Plot finden wir die n√∂tigen Informationen, welche wir brauchen, um das beste ```alpha``` zu finden.\n",
    "\n",
    "Von Interesse ist vor allem die orange Linie (```Testdaten```).\n",
    "\n",
    "Bei der Auswahl des besten ```alpha``` achten wir auf die folgenden zwei Punkte:\n",
    "1. Die ```Accuracy``` von ```test``` soll m√∂glichst gross sein\n",
    "2. Die ```Accuracy``` von ```train``` soll m√∂glichst gross sein\n",
    "\n",
    "Unter Anbetracht des aufgef√ºhrten Punktes ist das optimale ```alpha``` also der sechstletzte Punkt auf der ```test``` Linie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um den sechstletzten Punkt zu finden rufen wir nochmals die Liste mit den 'alpha' Werten auf\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimales 'alpha'\n",
    "alpha_opt = 0.01081731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_pruned = DecisionTreeClassifier(random_state=42,\n",
    "                                       ccp_alpha=alpha_opt)\n",
    "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotte den Entscheidungsbaum\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plot_tree(clf_dt_pruned,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accuracy' des neuen Entscheidungsbaumes\n",
    "predictions_new = clf_dt_pruned.predict(X_test)\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten die folgenden ```Accuracy-Werte```:\n",
    "* einfacher Entscheidungsbaum = ```0.746```\n",
    "* optimierter Entscheidungsbaum =  ```0.786```\n",
    "\n",
    "Wenn wir diese beiden Werte vergleichen, sehen wir, dass wir durch die Optimierung einen Entscheidungsbaum erhalten haben, welcher besser mit neuen Beobachtungen umgehen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Abschluss (5 min) <a class=\"anchor\" name=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was haben wir gelernt:\n",
    "* Was sind Entscheidungsb√§ume?\n",
    "* Wie lesen wir Entscheidungsb√§ume?\n",
    "* Wie bereiten wir Daten auf (fehlende Daten & Ausreisser)?\n",
    "* Arbeiten mit Trainings- und Testset\n",
    "* Erstellen von einfachen Entscheidungsb√§umen\n",
    "* Optimieren von einfachen Entscheidungsb√§umen\n",
    "* Accuracy und Confusion-Matrix\n",
    "\n",
    "Was muss man beachten, wenn man Modelle integrieren will:\n",
    "* Generalisierung\n",
    "* Software-Engineering-Skills um Modelle in Applikationen einzubinden\n",
    "* Antwortzeiten\n",
    "* Monitoren der Vorhersagequalit√§t\n",
    "* Zusammenarbeit von mehreren Rollen (Data-Engineer, Data-Scientist, Software-Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Anhang <a class=\"anchor\" name=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='anhang_1'></a>\n",
    "### Anhang 1: Anleitung Cross Complexity Pruning\n",
    "\n",
    "Der Algorithmus zur Kostenkomplexit√§tsbeschneidung folgt in der Regel diesen Schritten:\n",
    "\n",
    "1. Erstelle einen anf√§nglichen Entscheidungsbaum mit einem Trainingsdatensatz unter Ber√ºcksichtigung aller verf√ºgbaren Attribute und Merkmale.\n",
    "2. Bewerte die Klassifikationsleistung des Entscheidungsbaums anhand eines separaten Validierungsdatensatzes.\n",
    "3. Berechne f√ºr jeden internen Knoten des Entscheidungsbaums seine potenziellen Kosten in Bezug auf die fehlerhafte Klassifizierung oder anderer Metriken.\n",
    "4. Weise jedem internen Knoten eine Kostenkomplexit√§tswertung zu, die in der Regel als Summe seiner Kosten f√ºr fehlerhafte Klassifizierung und eines Strafterms berechnet wird, der proportional zur Anzahl der absteigenden Blattknoten ist.\n",
    "5. Beginnend beim Wurzelknoten beschneide iterativ den Knoten mit der niedrigsten Kostenkomplexit√§tswertung und erstellen eine Reihe von kleineren Entscheidungsb√§umen.\n",
    "6. Bewerte die Klassifikationsleistung jedes beschnittenen Entscheidungsbaums anhand des Validierungsdatensatzes.\n",
    "7. W√§hle den beschnittenen Baum mit der besten Leistung aus, die oft anhand der Genauigkeit oder einer anderen geeigneten Metrik gemessen wird.\n",
    "8. Optional kann man den ausgew√§hlten Baum weiter beschneiden, indem man den Komplexit√§tsparameter Œ± optimiert und die Schritte 5-7 wiederholt.\n",
    "9. Der endg√ºltige beschnittene Entscheidungsbaum wird erzielt, wenn durch zus√§tzliches Beschneiden keine weiteren Verbesserungen der Leistung erzielt werden k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 L√∂sungen <a class=\"anchor\" name=\"eight-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_1'></a>\n",
    "### L√∂sung Aufgabe 1\n",
    "\n",
    "Klassen:\n",
    "- Datenobjekt 1 = 'Has Insurance'\n",
    "- Datenobjekt 2 = 'Has Insurance' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/L√∂sung_mit_Pfaden.png \"L√∂sung\").\n",
    "\n",
    "-> Zur√ºck zu [Aufgabe 1](#aufgabe_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_2'></a>\n",
    "### L√∂sung Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 2](#aufgabe_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_3'></a>\n",
    "### L√∂sung Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing = df_start[df_start['ca'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 3](#aufgabe_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_4'></a>\n",
    "### L√∂sung  Aufgabe 4\n",
    "\n",
    "Die folgenden Code-Zellen bilden eine m√∂gliche L√∂sung zu Aufgabe 4 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.0000000000001\n",
    "value_alpha = 0.0000000000001\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_1 = DecisionTreeClassifier(random_state=42,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_1.fit(X_train, y_train)\n",
    "\n",
    "# plotte den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_1,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.01425422\n",
    "value_alpha = 0.01425422\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_2 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_2.fit(X_train, y_train)\n",
    "\n",
    "# plotte den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_2,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.2\n",
    "value_alpha = 0.2\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_3 = DecisionTreeClassifier(random_state=42,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_3.fit(X_train, y_train)\n",
    "\n",
    "# plotte den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_3,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 4](#aufgabe_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_5'></a>\n",
    "### L√∂sung  Aufgabe 5\n",
    "Die folgenden Code-Zellen bilden eine m√∂gliche L√∂sung zu Aufgabe 5 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifizierungen\n",
    "predictions = clf_dt_1.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_1.classes_)\n",
    "\n",
    "# plotten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plottet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifizierungen\n",
    "predictions = clf_dt_2.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_2.classes_)\n",
    "\n",
    "# plotten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plottet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifizierungen\n",
    "predictions = clf_dt_3.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_3.classes_)\n",
    "\n",
    "# plotten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plottet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 5](#aufgabe_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Quellen <a class=\"anchor\" name=\"nineth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#169; Quellen:\n",
    "&#128190; **Daten:** https://archive.ics.uci.edu/dataset/45/heart+disease \n",
    "<br>\n",
    "&#128252;  **Video:** https://youtu.be/q90UDEgYqeI?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB\n",
    "\n",
    "### &#128161; Weitere Informationen:\n",
    "\n",
    "``` Decision Trees: ``` &nbsp; https://www.youtube.com/watch?v=7VeUPuFGJHk&t=0s\n",
    "<br>\n",
    "``` Cross Validation: ``` &nbsp; https://www.youtube.com/watch?v=fSytzGwwBVw&t=0s\n",
    "<br>\n",
    "``` Confusion Matrix: ``` &nbsp; https://www.youtube.com/watch?v=Kdsp6soqA7o&t=0s\n",
    "<br>\n",
    "``` Cost-Complexity Pruning: ``` &nbsp; https://www.youtube.com/watch?v=D0efHEJsfHo&t=0s\n",
    "<br>\n",
    "``` Bias and Variance and Overfitting: ``` &nbsp; https://www.youtube.com/watch?v=EuBBz3bI-aA&t=0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
