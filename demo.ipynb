{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#127794; Digital Champion - Python Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wichtig: Diese beiden Zeilen m√ºssen zwingend ausgef√ºhrt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L√§dt unseren Datensatz herunter\n",
    "!git clone https://github.com/LearningFridayPost/dc-jupyter-notebook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Ñndert working directory, sodass Daten korrekt eingelesen werden k√∂nnen.\n",
    "%cd dc-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#128210; Inhaltsverzeichnis:\n",
    "* [1 Einf√ºhrung](#first-bullet)\n",
    "* [2 Entscheidungsb√§ume Theorie & Aufgabenstellung](#second-bullet)\n",
    "* [3 Datenaufbereitung](#third-bullet)\n",
    "* [4 Einfacher Entscheidungsbaum](#fourth-bullet)\n",
    "* [5 Optimierter Entscheidungsbaum](#fifth-bullet)\n",
    "* [6 Abschluss](#sixth-bullet)\n",
    "* [7 Anhang](#seventh-bullet)\n",
    "* [8 L√∂sungen](#eight-bullet)\n",
    "* [9 Quellen](#nineth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Einf√ºhrung (5 min) <a class=\"anchor\" name=\"first-bullet\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks sind interaktive Entwicklungsumgebungen, die es erm√∂glichen, Code, Visualisierungen und Text in einer einzigen Umgebung zu kombinieren. Sie werden h√§ufig f√ºr die Datenanalyse, den Code-Austausch und die Dokumentation verwendet. Mit Jupyter Notebooks k√∂nnen Python-Codezellen ausgef√ºhrt und die Ergebnisse sofort angezeigt werden. In diesem Jupyter-Notebook werden wir ```Entscheidungsb√§ume``` betrachten.\n",
    "\n",
    "![alt text for screen readers](./pictures/jupyter_intro_google.png \"Einf√ºhrung Jupyter Notebook\").\n",
    "\n",
    "### Erkl√§rungen:\n",
    "* &#10133; **Hinzuf√ºgen einer neuen Zelle:** Mit diesem Symbol k√∂nnen wir eine neue Zelle in das Notebook einf√ºgen\n",
    "* üóëÔ∏è **L√∂schen:** Mit diesem Symbol k√∂nnen wir eine Zelle l√∂schen und deren Inhalt entfernen\n",
    "* &#9654; **Ausf√ºhren:** Mit diesem Symbol k√∂nnen wir den Code in einer Zelle ausf√ºhren\n",
    "* ```Laufzeit``` -> ```Alle ausf√ºhren``` Es kann sein, dass der Kernel nicht mehr verbunden ist. In diesem Fall m√ºssen wir den Kernel neustarten und alle Zellen neu laufen lassen\n",
    "* ```Text``` Markdown-Zellen dienen zur Eingabe und Formatierung von Text. Sie erm√∂glichen es, Text, √úberschriften, Aufz√§hlungen, Bilder und andere Formatierungselemente einzuf√ºgen\n",
    "* ```Code``` Code-Zellen werden verwendet, um ausf√ºhrbaren Code einzugeben. In einer Code-Zelle k√∂nnen Programmiersprachen wie Python, R, Julia und andere verwendet werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "- Wir lesen das Notebook durch und bearbeiten die Aufgaben direkt in diesem Notebook\n",
    "    \n",
    "- Die L√∂sungen k√∂nnen wir mit dem Link unter den Aufgaben aufrufen\n",
    "    \n",
    "- Fragen bitte direkt in den Chat schreiben\n",
    "\n",
    "- Komplexere Fragen werden in Breakout-Sessions behandelt\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Entscheidungsb√§ume Theorie & Aufgabenstellung (8 min) <a class=\"anchor\" name=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Was ist ein Entscheidungsbaum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidungsb√§ume sind eine Methode zur automatischen Klassifizierung von Datenobjekten (z.B. Personen etc.) und damit zur L√∂sung von Entscheidungsproblemen. Ein Entscheidungsbaum besteht immer aus einem Wurzelknoten (root node) und beliebig vielen inneren Knoten (split node) sowie mindestens zwei Bl√§ttern (leaf node). Dabei repr√§sentiert jeder Knoten eine logische Regel und jedes Blatt eine Antwort auf das Entscheidungsproblem. Im Folgenden ist ein Beispiel f√ºr einen Entscheidungsbaum abgebildet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/dt-example-new.png \"Beispiel Entscheidungsbaum\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem abgebildeten Entscheidungsbaum wollen wir mit den Informationen von ```income_usd``` und ```with_mortage``` herausfinden, ob eine Person eine Versicherung hat.\n",
    "\n",
    "Die folgenden Informationen sind √ºblicherweise im Entscheidungsbaum abgebildet:\n",
    "* **gini:** Der Gini-Index beschreibt, wie gut ein Knoten verschiedene Klassen (z.B. ```No Insurance```, ```Has Insurance```) separiert. Der Wert ist immer zwischen 0 und 1. Je kleiner der Gini-Index ist desto besser. Bei der Konstruktion des Entscheidungsbaumes kann der Gini-Index berechnet werden. Es wird immer die logische Regel gew√§hlt, welche den besten Gini-Index aufweist.\n",
    "* **samples:** Dieser Wert beschreibt die Anzahl Beobachtungen (z.B. Daten von Personen), welche f√ºr den Split eines spezifischen Knoten zur Verf√ºgung stehen. Wir sehen beispielsweise, dass f√ºr die Konstruktion dieses Baumes Daten von 24 Personen verwendet wurden. Weiter sehen wir, dass der erste Knoten die 24 Personen in eine Gruppe mit 13 und eine Gruppe mit 11 Personen aufteilt.\n",
    "* **value:** Value beschreibt, wie die Aufteilung der ```samples``` im Knoten aussieht. Der Wert ```[15, 9]``` im ersten Knoten beschreibt beispielsweise, dass von 24 Personen 15 keine Versicherung und 9 Personen eine Versicherung haben.\n",
    "* **class:** Dieser Wert steht f√ºr die Klasse, f√ºr welche ein spezifischer Knoten steht. Beispiel: Im ersten Knoten sehen wir, die Klasse ```No insurance```, da von den 24 Personen mehr ```No Insurance``` (15) haben, als ```Has Insurance``` (9). Anhand der Farbe kann ebenfalls die Klasse abgelesen werden. Je r√∂ter ein Knoten ist, je mehr geh√∂rt er zur Klasse ```No Insurance``` und je blauer ein Knoten ist, je mehr geh√∂rt er zur Klasse ```Has Insurance```.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>\n",
    "Wie kann man einen Entscheidungsbaum lesen bzw. wie klassifizert der Entscheidungsbaum neue Beobachtungen (z.B. Personen):\n",
    "\n",
    "- Wir starten immer beim Wurzelknoten, d.h. ganz oben im Entscheidungsbaum\n",
    "\n",
    "- Wenn die logische Regel im Knoten f√ºr die neue Beobachtung erf√ºllt ist, geht man nach links und wenn sie nicht erf√ºllt ist, geht man nach rechts\n",
    "\n",
    "- Wir durchlaufen den Baum so lange, bis wir bei einem Blatt ankommen. Das ```class``` Attribute im Blatt beschreibt die Klasse des neuen Datenobjekts \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_1'></a>\n",
    "&#9989; **AUFGABE 1:**</b> Bestimme die Klasse der beiden nachfolgeden Personen anhand des oben abgebildeten Entscheidungsbaums:\n",
    "\n",
    "- Person 1: income_usd = 100'000; with_mortage = 0\n",
    "\n",
    "- Person 2: income_usd = 73'000; with_mortage = 1\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 1](#l√∂sung_aufgabe_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung (mit # Kommentarfunktion):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Aufgabenstellung\n",
    "\n",
    "In diesem Jupyter-Notebook arbeiten wir mit dem ['heart-disease'](https://archive.ics.uci.edu/dataset/45/heart+disease) (HD) Datenset. Das Datenset ist eine Tabelle mit 14 Spalten (Features) und 303 Zeilen (Beobachtungen). Eine kurze Beschreibung der verschiedenen Features:\n",
    "* age: Alter\n",
    "* sex: Mann/Frau\n",
    "* restbp: resting blood pressure (Ruheblutdruck (in mm Hg bei Aufnahme ins Krankenhaus))\n",
    "* chol: Serumcholesterin in mg/dl\n",
    "* fbs: wenn der N√ºchternblutzucker > 120 mg/dl liegt\n",
    "* thalach: maximale Herzfrequenz erreicht\n",
    "* exang: Belastungsangina (Richtig/Falsch)\n",
    "* oldpeak: ST-Depression durch k√∂rperliche Bet√§tigung im Vergleich zur Ruhe\n",
    "* ca: Anzahl der gro√üen Gef√§√üe (0-3), gef√§rbt durch Fluoroskopie\n",
    "* hd: Art der Herzerkrankung\n",
    "\n",
    "Unser Ziel ist es, mit den 303 Beobachtungen ein Modell zu generieren, welches neue Beobachtungen (bzw. Personen) klassifizieren und somit bestimmen kann, ob eine Herzerkrankung (HD) vorliegt oder nicht. Im Modell nutzen wir die oben beschriebenen Features um die Zielvariable (HD) vorherzusagen:\n",
    "\n",
    "Wir verwenden einen Entscheidungsbaum f√ºr die Klassifikation von HD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Datenaufbereitung (12 min) <a class=\"anchor\" name=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read data\n",
    "\n",
    "Bei jedem neuen Python-Projekt √ºberlegen wir uns, welche Python-Bibliotheken wir verwenden m√∂chten. Eine Python-Bibliothek ist ein wiederverwendbarer Codeblock, den wir in einem Programm bzw. Projekt einbinden k√∂nnen. Das Einbinden von solchen Codeblocks ist einiges schneller als den Code selber zu schreiben.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "Wenn wir in Python programmieren, ist es wichtig zu wissen, dass alles was hinter einem '#' steht kein Code ist, sondern nur ein Kommentar um den Code zu beschreiben. </div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "# pandas: Daten lesen und bearbeiten\n",
    "import pandas as pd\n",
    "# numpy: berechnen von KPIs\n",
    "import numpy as np\n",
    "# plt: ploten von Grafiken\n",
    "import matplotlib.pyplot as plt\n",
    "# DecisionTreeClassifier: Modellierungskit f√ºr Entscheidungsb√§ume\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# plot_tree: Entscheidungsbaum als Grafik ploten\n",
    "from sklearn.tree import plot_tree\n",
    "# train_test_split: Hilfe um Testobjekte in Training- bzw. Testset zu splitten\n",
    "from sklearn.model_selection import train_test_split\n",
    "# cross_val_score: Kreuzvalidierung\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# confusion_matrix: Konfusionsmatrix ploten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# ConfusionMatrixDispla: Konfusionsmatrix ploten\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# accuracy_score: berechne die Accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>   In Python kann man mit Hilft des '=' Operatros Daten in einer Variable speichern. Wenn wir beispielsweise die Zahl 5 in der Variable 'a' speichern m√∂chten, k√∂nnen wir das mit dem folgenden Code machen:\n",
    "<br><br>\n",
    "a = 5 \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(filepath_or_buffer, sep, encoding) erm√∂glicht es '.csv' Daten einzulesen\n",
    "# und in einer Variable als Tabelle zu speichern\n",
    "df = pd.read_csv(filepath_or_buffer='data/processed_cleveland_small.csv',\n",
    "                 sep=',',\n",
    "                 encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn wir eine Variable aufrufen, wird sie geplottet\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_2'></a>\n",
    "&#9989; **AUFGABE 2:**</b>\n",
    "Speichere die Daten in der Variable 'df_start'\n",
    "    \n",
    "-> L√∂sungen zu [Aufgabe 2](#l√∂sung_aufgabe_2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() zeigt, wie die ersten f√ºnf Spalten in der Tabelle aussehen\n",
    "df_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fehlenden Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir den Spaltennamen in eckige Klammer schreiben, z.B. ['Spaltenname'], erhalten wir die Werte dieser Spalte\n",
    "df_start['ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte geplotete Wert ist ein '?'. Wir wollen kurz pr√ºfen, ob es noch mehr solche 'speziellen' Werte gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .unique() zeigt allte einzigartigen Elemente in der Spalte 'ca'\n",
    "df_start['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da '?' der einzige 'spezielle' Werte in der Spalte ist, nehmen wir an, es sind fehlende Daten.\n",
    "\n",
    "Um zu sehen, wie viel mal dieser Wert vorkommt, filtern wir danach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Tabellenname['Spaltenname'] == 'zu pr√ºfender Text'] so kann eine Tabelle nach einem spezifischen Spaltenwert gefiltert werden\n",
    "df_start[df_start['ca'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Wert '?' kommt nur wenige Male vor. Aus diesem Grund entfernen wir jede Beobachtung mit einem Fragezeichn. Fehlende Daten k√∂nnen zu Fehleren in der Konstruktion von Entscheidungsb√§umen f√ºhren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>  Die wichtigsten Vergleichsoperatoren:\n",
    "    \n",
    "* ==: zu vergleichendes Element muss den gleichen Inhalt haben\n",
    "* !=: zu vergleichendes Element darf nicht den gleichen Inhalt haben\n",
    "* \\>=: zu vergleichende Zahl muss gleich gr√∂sser sein\n",
    "* <=: zu vergleichende Zahl muss gleich kleiner sein\n",
    "     \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_3'></a>\n",
    "&#9989; **AUFGABE 3:**</b>\n",
    "Wir haben gesehen, dass nur 4 Testobjekte in der Spalte 'ca' ein '?' enthalten. Weil es nur so wenige Testobjekte sind, wollen wir diese aus unserer 'df_start' Tabelle rausfiltern und die neue Tabelle unter 'df_no_missing' speichern.\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 3](#l√∂sung_aufgabe_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier pr√ºfen wir, ob wir alle '?' entfernt haben\n",
    "df_no_missing['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ausreisser\n",
    "\n",
    "Bei dem folgenden Feature vermuten wir Ausreisser (Outliers):\n",
    "* age\n",
    "\n",
    "Eine M√∂glichkeit Daten auf Ausreisser zu pr√ºfen sind Boxplots. Boxplots zeigen wie die Daten verteilt sind.\n",
    "\n",
    "![alt text for screen readers](./pictures/boxplot-new.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .boxplot(Spaltenname) plottet einen Boxplot einer Tabellenspalte\n",
    "df_no_missing.boxplot('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass es im Feature ```age``` keine Ausreisser hat. Falls Ausreisser vorkommen, sollte man diese entfernen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Daten formatieren\n",
    "In einem n√§chsten Schritt m√ºssen wir die Daten zweiteilen. Alle Features kommen in die Tabelle ```X```. Die Werte der Zielvariablen kommen in die Tabelle ```y```.\n",
    "\n",
    "```X``` stellt potentielle Beobachtungen (Daten von Personen) dar und ```y``` steht f√ºr die potentiellen Klassifizierungen (```0```=```keine HD```; ```1```=```hat HD```).\n",
    "\n",
    "Das Ziel wird es sp√§ter sein, einen Entscheidungsbaum zu konstruieren welcher ```y``` m√∂glichst richtig klassifiziert in Abh√§ngigkeit von ```X```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit .copy() kopieren wir eine Variable in eine neue Variable\n",
    "df_clean = df_no_missing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in diesem Schritt speichern wir alle Features in 'X'\n",
    "# .drop('Spaltenname', axis=1) kann verwendet werden um eine Spalte zu entfernen\n",
    "# mit .copy() kopieren wir das Resultat in eine neue Variable\n",
    "X = df_clean.drop('hd', axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in diesem Schritt speichern wir alle Zielvariablen in 'y'\n",
    "y = df_clean['hd'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im n√§chsten Schritt unterteilen wir unsere Daten in ein ```Trainings-``` und in ein ```Testset```:\n",
    "- ```Trainingsset```: Wird verwendet, um einen Entscheidungsbaum abh√§ngig von spezifische Beobachtungen zu konstruieren (bzw. trainieren) und ihm die spezifischen Eigenschaften eines Datensatzes mit Beobachtungen beizubringen\n",
    "- ```Testset```: Wird verwendet, um den Entscheidungsbaum zu testen und zu kontrollieren, wie gut er neue Beobachtungen klassifizieren kann.\n",
    "\n",
    "![alt text for screen readers](./pictures/train_test_split.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split(X, y) teilt die Daten in ein Trainings- und in ein Testset\n",
    "# Standardm√§√üig sind im Testset 25% der Daten vorhanden und im Trainingsset 75%\n",
    "# wir sehen, dass train_test_split() 4 Tabellen generiert (je ein X und y Tabelle f√ºr beide Sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Einfacher Entscheidungsbaum (10 min) <a class=\"anchor\" name=\"fourth-bullet\"></a>\n",
    "### 4.1 Einfacher Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt konstruieren wir einen ```einfachen Entscheidungsbaum``` (ohne Optimierungen) abh√§ngig von unseren Beobachtungen im Trainingsset.\n",
    "\n",
    "Im n√§chsten Abschnitt konstruieren wir einen ```opitmierten Entscheidungsbaum``` abh√§ngig von unseren Beobachtungen im Trainingsset und vergleichen diesern mit dem ```einfachen Entscheidungsbaum```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTressClassifier() √ºbernimmt f√ºr uns das erstellen eines Entscheidungsbaumes\n",
    "clf_dt_e = DecisionTreeClassifier(random_state=42)\n",
    "# .fit(X_train, y_train) weist dem Entscheidungsbaum ein Trainingsset (X und y) zu\n",
    "clf_dt_e.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mit den folgenden Zeilen k√∂nnen wir einen Entscheidungsbaum plotten\n",
    "# hier wird die gr√∂sse des plotts definiert (15 steht f√ºr die Breite und 7.5 steht f√ºr die H√∂he)\n",
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# plot_tree(decision_tree, class_names, feature_names) √ºbernimmt das visualisieren eines Entscheidungsbaumes f√ºr uns\n",
    "# 'decision_tree' steht f√ºr den Entscheidungsbaum der visualisiert werden soll\n",
    "plot_tree(decision_tree=clf_dt_e,\n",
    "          # 'filled=True' so werden die Knoten mit Farben gef√ºllt\n",
    "          filled=True,\n",
    "          # 'class_names=[\"kein HD\", \"hat HD\"]' Klassen die in jedem Knoten unter 'class' stehen sollen\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          # 'feature_names=X.columns' muss mitgegeben werden, dass die Features im Plot korrekt bezeichnet werden\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem ersten Schritt haben wir einen Entscheidungsbaum gebaut. Jetzt wollen wir sehen, wie gut dieser Entscheidungsbaum, welchen wir mit den Trainingsset trainiert haben, Klassifizierungen im Testset vornehmen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .predict(Tabellenname) kann f√ºr Klassifizierungen gebraucht werden\n",
    "# als Input muss dieser Funktion ein Tabellenname mitgegeben werden -> die Tabelle muss die Test-Features enthalten\n",
    "predictions = clf_dt_e.predict(X_test)\n",
    "# der Output ist eine Liste mit den Klassifizierungen (0=keine HD; 1=hat HD)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem n√§chsten Schritt wollen wir pr√ºfen, ob diese Klassifizierungen richtig oder falsch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_true, y_pred, labels) bietet uns eine M√∂glichkeit f√ºr so eine Pr√ºfung\n",
    "# 'y_true' -> Liste der korrekten Klassifizierungen\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      # 'y_pred' -> Liste der vogenommenen Klassifizierungen\n",
    "                      y_pred=predictions,\n",
    "                      # 'labels' -> Klassen von clf_dt mitgeben\n",
    "                      labels=clf_dt_e.classes_)\n",
    "\n",
    "# ConfusionMatrixDisplay(confusion_matrix, display_labels) ist eine M√∂glichkeit die Confusion-Matrix 'cm' zu visualisieren\n",
    "# 'confusion_matrix' -> Confusion-Matrix die visualisiert werden soll\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              # 'display_labels' -> welche Labels sollen auf der Visualisierung dargestellt werden\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die oben abgebildete Grafik zeigt eine ```Confusion-Matrix```. Wie lesen wir diese:\n",
    "- 31: Haben keine Herzkrankheit -> Diese 31 haben wir korrekt klassifiziert (True Negative TN) <br>\n",
    "- 12: Haben keine Herzkrankheit -> Diese 12 haben wir falsch klassifiziert (False Negative FN) <br>\n",
    "- 25: Haben eine Herzkrankheit -> Diese 25 haben wir korrekt klassifiziert (True Positive TP) <br>\n",
    "- 7: Haben eine Herzkrankheit -> Diese 7 haben wir falsch klassifiziert (False Positive FP)\n",
    "\n",
    "Wie gut ein Entscheidungsbaum ist, definieren wir anhand der ```Accuracy```. Welche mit Hilfe der ```Confusion-Matrix``` berechnet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "<br>\n",
    "<br>... bei unserem einfachen Entscheidungsbaum haben wir z.B. folgende accuracy:\n",
    "<br> \n",
    "<br>Accuracy = (25 + 31) / (25 + 31 + 7 + 12) = 0.75\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_true, y_pred) liefert ebenfalls die korrekte Accuracy\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Optimierter Entscheidungsbaum (10 min) <a class=\"anchor\" name=\"fifth-bullet\"></a>\n",
    "### 5.1 Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/ccp.png \"Pruning\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben einen ```einfachen Entscheidungsbaum``` konstruiert. Dieser Entscheidungsbaum ist auf unser Trainigsset √ºberangepasst. Das heisst, er funktioniert sehr gut f√ºr die Klassifizierung von Beobachtungen aus unserem Trainigsset aber weniger gut f√ºr die Klassifizierung von neuen Beobachtungen.\n",
    "\n",
    "Dieses Problem k√∂nnen wir l√∂sen, indem wir verschiedene Arten von Parametern verwenden (z. B. ```max_ Depth``` oder ```min_samples```) und den Entscheidungsbaum optimieren bzw. vereinfachen (weniger Bl√§tter). Diesen Prozess nennt man ```Pruning```.\n",
    "\n",
    "```Pruning``` sollte die ```Accuracy``` im Bezug auf neue Beobachtungen verbessern.\n",
    "\n",
    "```Cost Complexity Pruning``` ist eine spezifische Methode, um einen kleineren Baum zu finden, der bessere Ergebnisse mit neuen Beobachtungen liefert. Wir schauen, ob kleinere Teil-Entscheidungsb√§ume (Baum mit 38 Bl√§tter, Baum mit 37 Bl√§tter, etc.) bessere Ergebnisse liefern als gr√∂ssere. Damit kleinere B√§ume mit gr√∂sseren B√§umen verglichen werden k√∂nnen, verwenden wir ```alpha``` als eine Art Penalty, der das Ergebniss von kleineren B√§umen verbessert (√úberanpassung kontra. Genauigkeit im Testdatenset).\n",
    "\n",
    "Eine genauere Anleitung zum ```Cross Complexity Pruning``` findet ihr [hier](#anhang_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "Die Werte von ```alpha``` sind wie folgt zu interpretieren:\n",
    "- 0: Der Entscheidungsbaum ist nicht geprunt (maximale Gr√∂sse)\n",
    "- je gr√∂sser ```alpha``` desto einfacher (weniger Bl√§tter) ist der Entscheidungsbaum\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .cost_complexity_pruning_path(X_train, y_train) ist ein Algorithmus\n",
    "# der als Ergebniss wichtige 'alpha' Parameter liefert, welche es zu √úberpr√ºfen gilt\n",
    "path = clf_dt_e.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.0077381\n",
    "value_alpha = 0.0077381\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_new = DecisionTreeClassifier(random_state=42,\n",
    "                                    ccp_alpha=value_alpha)\n",
    "clf_dt_new.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_new,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_4'></a>\n",
    "&#9989; **AUFGABE 4:**</b>\n",
    "\n",
    "Kontruiere und plote drei verschiedene Entscheidungsb√§ume mit verschiedenen 'alpha' Values. F√ºr die Konstruktion kannst du den obigen Code verwenden bzw. kopieren.\n",
    "    \n",
    "Bitte stelle sicher, dass du die Entscheidungsb√§ume in den folgenden Variablen abspeicherst:\n",
    "- clf_dt_1\n",
    "- clf_dt_2\n",
    "- clf_dt_3\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 4](#l√∂sung_aufgabe_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f√ºr den konstruierten Entscheidungsbaum 'clf_dt_new' wollen wir die Confusion-Matrix plotten, um zu sehen, wie gut er performt\n",
    "# Klasifizierungen\n",
    "predictions = clf_dt_new.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_new.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_5'></a>\n",
    "&#9989; **AUFGABE 5:**</b>\n",
    "\n",
    "Plote die Confusion-Matrix f√ºr die in Aufgabe 4 kosnstruierten Entscheidungsb√§ume. F√ºr die Plots kannst du den obigen Code verwenden bzw. kopieren.\n",
    "<br>\n",
    "<br>-> L√∂sungen zu [Aufgabe 5](#l√∂sung_aufgabe_5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt gesehen, dass je nach ```alpha``` die Ergebnisse schlechter oder besser werden. Die Frage ist jetzt, wie finden wir auf eine einfache Art dasjenige 'alpha', bei welchem die Ergebnisse am besten sind.\n",
    "\n",
    "Wir schreiben einen Code der folgendes f√ºr uns erledigt:\n",
    "1. Einen Entscheidungsbaum pro ```alpha``` Wert konstruieren\n",
    "2. Pro Entscheidungsbaum die ```Accuracy``` f√ºr das Testset und das Trainingsset rechnen\n",
    "3. Die ```Accuracy``` f√ºr jeden Entscheidungsbaum in Abh√§ngigkeit von ```alpha``` ploten\n",
    "\n",
    "Der Code, welcher dies f√ºr uns ausf√ºhrt, findet ihr untenstehend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Komplexe Code-Zelle:</b> \n",
    "\n",
    "Die nachfolgenden Code-Zelle muss nur ausgef√ºhrt werden. Das Nachvollziehen der Funktionsweise ist nicht Teil dieser Einf√ºhrung, dies w√ºrde √ºber den Scope hinaus gehen.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit [:-1] entfernen wir den gr√∂ssten 'alpha' Wert (das gr√∂sste 'alpha' hat keine Bl√§tter)\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "clf_dts = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    clf_dts.append(clf_dt)\n",
    "    \n",
    "# mit dem untenstehenden Code plotten wir 'Accuracy' in Abh√§ngigkeit zu 'alpha' (f√ºr Testdaten und Trainingsdaten)\n",
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im obigen Plot finden wir die n√∂tigen Informationen, welche wir brauchen, um das beste ```alpha``` zu finden.\n",
    "\n",
    "Von Interesse ist vor allem die orange Linie (```Testdaten```).\n",
    "\n",
    "Bei der Auswahl des besten ```alpha``` achten wir auf die folgenden zwei Punkte:\n",
    "1. Die ```Accuracy``` von ```test``` soll m√∂glichst gross sein\n",
    "2. Die ```Accuracy``` von ```train``` soll m√∂glichst gross sein\n",
    "\n",
    "Unter Anbetracht des aufgef√ºhrten Punktes, ist das optimale ```alpha``` also der sechstletzte Punkt auf der ```test``` Linie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um den sechstletzten Punkt zu finden rufen wir nochmals die Liste mit den 'alpha' Werten auf\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimales 'alpha'\n",
    "alpha_opt = 0.01081731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_pruned = DecisionTreeClassifier(random_state=42,\n",
    "                                       ccp_alpha=alpha_opt)\n",
    "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotte den Entscheidungsbaum\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plot_tree(clf_dt_pruned,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accuracy' des neuen Entscheidungsbaumes\n",
    "predictions_new = clf_dt_pruned.predict(X_test)\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten die folgenden ```Accuracy-Werte```:\n",
    "* einfacher Entscheidungsbaum = ```0.746```\n",
    "* optimierter Entscheidungsbaum =  ```0.786```\n",
    "\n",
    "Wenn wir diese beiden Werte vergleichen, sehen wir, dass wir durch die Optimierung einen Entscheidungsbaum erhalten haben, welcher besser mit neuen Beobachtungen umgehen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Abschluss (5 min) <a class=\"anchor\" name=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was haben wir gelernt:\n",
    "* Was sind Entscheidungsb√§ume?\n",
    "* Wie lesen wir Entscheidungsb√§ume?\n",
    "* Wie bereiten wir Daten auf (fehlende Daten & Ausreisser)?\n",
    "* Arbeiten mit Trainings- und Testset\n",
    "* Erstellen von einfachen Entscheidungsb√§umen\n",
    "* Optimieren von einfachen Entscheidungsb√§umen\n",
    "* Accuracy und Confusion-Matrix\n",
    "\n",
    "Was muss man beachten, wenn man Modelle integrieren will:\n",
    "* Generalisierung\n",
    "* Software-Engineering-Skills um Modelle in Applikationen einzubinden\n",
    "* Antwortzeiten\n",
    "* Monitoren der Vorhersagequalit√§t\n",
    "* Zusammenarbeit von mehreren Rollen (Data-Engineer, Data-Scientist, Software-Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Anhang <a class=\"anchor\" name=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='anhang_1'></a>\n",
    "### Anhang 1: Anleitung Cross Complexity Pruning\n",
    "\n",
    "Der Algorithmus zur Kostenkomplexit√§tsbeschneidung folgt in der Regel diesen Schritten:\n",
    "\n",
    "1. Erstelle einen anf√§nglichen Entscheidungsbaum mit einem Trainingsdatensatz unter Ber√ºcksichtigung aller verf√ºgbaren Attribute und Merkmale.\n",
    "2. Bewerte die Klassifikationsleistung des Entscheidungsbaums anhand eines separaten Validierungsdatensatzes.\n",
    "3. Berechne f√ºr jeden internen Knoten des Entscheidungsbaums seine potenziellen Kosten in Bezug auf die fehlerhafte Klassifizierung oder andere Metriken.\n",
    "4. Weise jedem internen Knoten eine Kostenkomplexit√§tswertung zu, die in der Regel als Summe seiner Kosten f√ºr fehlerhafte Klassifizierung und eines Strafterms berechnet wird, der proportional zur Anzahl der absteigenden Blattknoten ist.\n",
    "5. Beginnend beim Wurzelknoten beschneide iterativ den Knoten mit der niedrigsten Kostenkomplexit√§tswertung und erstellen eine Reihe von kleineren Entscheidungsb√§umen.\n",
    "6. Bewerte die Klassifikationsleistung jedes beschnittenen Entscheidungsbaums anhand des Validierungsdatensatzes.\n",
    "7. W√§hle den beschnittenen Baum mit der besten Leistung aus, die oft anhand der Genauigkeit oder einer anderen geeigneten Metrik gemessen wird.\n",
    "8. Optional kann man den ausgew√§hlten Baum weiter beschneiden, indem man den Komplexit√§tsparameter Œ± optimiert und die Schritte 5-7 wiederholt.\n",
    "9. Der endg√ºltige beschnittene Entscheidungsbaum wird erzielt, wenn durch zus√§tzliches Beschneiden keine weiteren Verbesserungen der Leistung erzielt werden k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 L√∂sungen <a class=\"anchor\" name=\"eight-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_1'></a>\n",
    "### L√∂sung Aufgabe 1\n",
    "\n",
    "Klassen:\n",
    "- Datenobjekt 1 = 'Has Insurance'\n",
    "- Datenobjekt 2 = 'Has Insurance' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/L√∂sung_mit_Pfaden.png \"L√∂sung\").\n",
    "\n",
    "-> Zur√ºck zu [Aufgabe 1](#aufgabe_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_2'></a>\n",
    "### L√∂sung Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 2](#aufgabe_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_3'></a>\n",
    "### L√∂sung Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing = df_start[df_start['ca'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 3](#aufgabe_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_4'></a>\n",
    "### L√∂sung  Aufgabe 4\n",
    "\n",
    "Die folgenden Code-Zellen bilden eine m√∂gliche L√∂sung zu Aufgabe 4 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.0000000000001\n",
    "value_alpha = 0.0000000000001\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_1 = DecisionTreeClassifier(random_state=42,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_1.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_1,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.01425422\n",
    "value_alpha = 0.01425422\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_2 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_2.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_2,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.2\n",
    "value_alpha = 0.2\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_3 = DecisionTreeClassifier(random_state=42,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_3.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_3,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 4](#aufgabe_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_5'></a>\n",
    "### L√∂sung  Aufgabe 5\n",
    "Die folgenden Code-Zellen bilden eine m√∂gliche L√∂sung zu Aufgabe 5 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_1.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_1.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_2.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_2.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_3.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_3.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 5](#aufgabe_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Quellen <a class=\"anchor\" name=\"nineth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#169; Quellen:\n",
    "&#128190; **Daten:** https://archive.ics.uci.edu/dataset/45/heart+disease \n",
    "<br>\n",
    "&#128252;  **Video:** https://youtu.be/q90UDEgYqeI?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB\n",
    "\n",
    "### &#128161; Weitere Informationen:\n",
    "\n",
    "``` Decision Trees: ``` &nbsp; https://www.youtube.com/watch?v=7VeUPuFGJHk&t=0s\n",
    "<br>\n",
    "``` Cross Validation: ``` &nbsp; https://www.youtube.com/watch?v=fSytzGwwBVw&t=0s\n",
    "<br>\n",
    "``` Confusion Matrix: ``` &nbsp; https://www.youtube.com/watch?v=Kdsp6soqA7o&t=0s\n",
    "<br>\n",
    "``` Cost-Complexity Pruning: ``` &nbsp; https://www.youtube.com/watch?v=D0efHEJsfHo&t=0s\n",
    "<br>\n",
    "``` Bias and Variance and Overfitting: ``` &nbsp; https://www.youtube.com/watch?v=EuBBz3bI-aA&t=0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
