{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#127794; Digital Champion - Hands-On Python Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#128210; Inhaltsverzeichnis:\n",
    "* [1 Einf√ºhrung](#first-bullet)\n",
    "* [2 Entscheidungsb√§ume Theorie & Aufgabenstellung](#second-bullet)\n",
    "* [3 Datenaufbereitung](#third-bullet)\n",
    "* [4 Einfacher Entscheidungsbaum](#fourth-bullet)\n",
    "* [5 Optimierter Entscheidungsbaum](#fifth-bullet)\n",
    "* [6 Abschluss](#sixth-bullet)\n",
    "* [7 Anhang](#seventh-bullet)\n",
    "* [8 L√∂sungen](#eight-bullet)\n",
    "* [9 Quellen](#nineth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Einf√ºhrung (5 min) <a class=\"anchor\" name=\"first-bullet\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks sind interaktive Entwicklungsumgebungen, die es erm√∂glichen, Code, Visualisierungen und Text in einer einzigen Umgebung zu kombinieren. Sie werden h√§ufig f√ºr die Datenanalyse, den Code-Austausch und die Dokumentation verwendet. Mit Jupyter Notebooks k√∂nnen Python-Codezellen ausgef√ºhrt und die Ergebnisse sofort angezeigt werden. In diesem Jupyter-Notebook werden wir ```Entscheidungsb√§ume``` betrachten.\n",
    "\n",
    "![alt text for screen readers](./pictures/jupyter_intro_google.png \"Einf√ºhrung Jupyter Notebook\").\n",
    "\n",
    "### Erkl√§rungen:\n",
    "* &#10133; **Code:** Mit diesem Symbol k√∂nnen wir eine neue Code-Zelle in das Notebook einf√ºgen. Die Code-Zellen werden dazu verwendet, um ausf√ºhrbaren Code einzugeben. In einer Code-Zelle k√∂nnen Programmiersprachen wie Python, R, Julia und andere verwendet werden.\n",
    "* &#10133; **Text:** Mit diesem Symbol k√∂nnen wir eine neue Text-Zelle in das Notebook einf√ºgen. Die Text-Zellen dienen zur Eingabe und Formatierung von Text. Sie erm√∂glichen es, Text, √úberschriften, Aufz√§hlungen, Bilder und andere Formatierungselemente einzuf√ºgen.\n",
    "* üóëÔ∏è **L√∂schen:** Mit diesem Symbol k√∂nnen wir eine Zelle l√∂schen und deren Inhalt entfernen.\n",
    "* &#9654; **Ausf√ºhren:** Mit diesem Symbol k√∂nnen wir den Code in einer Zelle ausf√ºhren.\n",
    "* ```Laufzeit``` -> ```Alle ausf√ºhren``` Der Kernel f√ºhrt den Code aus und gibt die Ergebnisse zur√ºck an das Notebook. Es kann sein, dass der Kernel nicht mehr verbunden ist. In diesem Fall m√ºssen wir den Kernel neustarten und alle Zellen neu laufen lassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wichtig: Diese beiden Zeilen m√ºssen zwingend ausgef√ºhrt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L√§dt unseren Datensatz aus dem LearningFriday GitHub Repository\n",
    "!git clone https://github.com/LearningFridayPost3/dc-jupyter-notebook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Ñndert working directory (Ordner, wo wir Daten suchen), damit Daten eingelesen werden k√∂nnen\n",
    "%cd dc-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "- Wir lesen das Notebook durch und bearbeiten die Aufgaben direkt in diesem Notebook\n",
    "    \n",
    "- Die L√∂sungen k√∂nnen wir mit dem Link unter den Aufgaben aufrufen\n",
    "    \n",
    "- Fragen bitte direkt in den Teams-Chat schreiben\n",
    "\n",
    "- Komplexere Fragen werden in Breakout-Sessions behandelt\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Entscheidungsb√§ume: Theorie & Aufgabenstellung (8 min) <a class=\"anchor\" name=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Was ist ein Entscheidungsbaum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidungsb√§ume sind eine Methode zur automatischen Klassifizierung von Datenobjekten (z.B. Personen oder Objekte wie etwa Pakete). Ein Entscheidungsbaum besteht immer aus einem Wurzelknoten (root node) und beliebig vielen inneren Knoten (split node) sowie mindestens zwei Bl√§ttern (leaf node). Dabei repr√§sentiert jeder Knoten eine logische Regel und jedes Blatt eine Klasse. Im Folgenden ist ein Beispiel f√ºr einen Entscheidungsbaum abgebildet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/dt-example-new.png \"Beispiel Entscheidungsbaum\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben einen Datensatz mit vielen Personen. F√ºr jede Person kennen wir das Einkommen und wissen, ob eine Person eine Hypothek hat. Die Zielgr√∂sse ist, ob eine bestimmte Person eine Versicherung hat (Klasse: ```Has Insurance```) oder nicht (Klasse: ```No Insurance```). Das heisst : Mit dem abgebildeten Entscheidungsbaum wollen wir mittels der Informationen von ```income_usd``` und ```with_mortage``` herausfinden, ob eine Person eine Versicherung hat.\n",
    "\n",
    "Die folgenden Informationen sind im Entscheidungsbaum (Abbildung oben) enthalten:\n",
    "* **gini:** Der Gini-Index beschreibt, wie gut ein Knoten verschiedene Klassen (z.B. ```No Insurance```, ```Has Insurance```) separiert. Der Wert ist immer zwischen 0 und 1. Je kleiner der Gini-Index ist, desto besser. Bei der Konstruktion des Entscheidungsbaumes wird bei jedem Knoten der Gini-Index berechnet. Es wird immer die logische Regel gew√§hlt, welche den kleinsten Gini-Index aufweist.\n",
    "* **samples:** Dieser Wert beschreibt die Anzahl Beobachtungen (z.B. Daten von Personen), welche f√ºr den Split eines spezifischen Knotens zur Verf√ºgung stehen. Wir sehen beispielsweise, dass f√ºr die Konstruktion dieses Baumes Daten von 24 Personen verwendet wurden. Weiter sehen wir, dass der erste Knoten die 24 Personen in eine Gruppe mit 13 und eine Gruppe mit 11 Personen aufteilt.\n",
    "* **value:** Value beschreibt, wie die Aufteilung der ```samples``` im Knoten aussieht. Der Wert ```[15, 9]``` im ersten Knoten beschreibt beispielsweise, dass von 24 Personen, 15 keine Versicherung (Klasse: ```No Insurance```) und 9 Personen eine Versicherung (Klasse: ```Has Insurance```) haben.\n",
    "* **class:** Dieser Wert zeigt die Klasse, welche einem spezifischen Knoten zugewiesen wird. Beispiel: Im ersten Knoten sehen wir die Klasse ```No Insurance```, da von den 24 Personen mehr ```No Insurance``` (15) haben, als ```Has Insurance``` (9). Wir k√∂nnen die Klasse auch ahhand der Farben ablesen. Je r√∂ter ein Knoten ist, desto eher geh√∂rt er zur Klasse ```No Insurance``` und je blauer ein Knoten ist, desto eher geh√∂rt er zur Klasse ```Has Insurance```.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>\n",
    "Wie kann man einen Entscheidungsbaum lesen bzw. wie klassifizert der Entscheidungsbaum neue Beobachtungen (z.B. Personen):\n",
    "\n",
    "- Wir starten immer beim Wurzelknoten, d.h. ganz oben im Entscheidungsbaum.\n",
    "\n",
    "- Wenn die logische Regel im Knoten f√ºr die neue Beobachtung erf√ºllt ist, wird der linke Pfad im Entscheidungsbaum gew√§hlt. Wenn die logische Regel im Knoten nicht erf√ºllt ist, wird der rechte Pfad gew√§hlt.\n",
    "\n",
    "- Wir durchlaufen den Entscheidungsbaum so lange, bis wir bei einem Blatt ankommen. Das ```class``` Attribut im Blatt beschreibt die Klasse des neuen Datenobjekts.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_1'></a>\n",
    "&#9989; **AUFGABE 1:**</b> Bestimme die Klasse der beiden nachfolgenden Personen gem√§ss des oben abgebildeten Entscheidungsbaums:\n",
    "\n",
    "- Person 1: income_usd = 100'000; with_mortgage = 0\n",
    "\n",
    "- Person 2: income_usd = 73'000; with_mortgage = 1\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 1](#l√∂sung_aufgabe_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung (mit # kann man Kommentare schreiben, die nicht interpretiert werden von Python):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Aufgabenstellung\n",
    "\n",
    "Nun arbeiten wir mit dem ['heart-disease'](https://archive.ics.uci.edu/dataset/45/heart+disease) (HD) Datenset. Diese Patientendaten sind in einer Tabelle mit 14 Spalten (Features) und 303 Zeilen (Beobachtungen) organisiert. Eine kurze Beschreibung der verschiedenen Features:\n",
    "* age: Alter in Jahren\n",
    "* sex: Mann/Frau\n",
    "* restbp: resting blood pressure (Ruheblutdruck in mm/Hg bei Aufnahme ins Krankenhaus)\n",
    "* chol: Serumcholesterin in mg/dl\n",
    "* fbs: wenn der N√ºchternblutzucker > 120 mg/dl liegt\n",
    "* thalach: maximale Herzfrequenz erreicht\n",
    "* exang: Belastungsangina vorhanden (Wahr/Falsch)\n",
    "* oldpeak: ST-Depression durch k√∂rperliche Bet√§tigung im Vergleich zur Ruhe\n",
    "* ca: Anzahl der gro√üen Gef√§√üe (0-3), gef√§rbt durch Fluoroskopie\n",
    "\n",
    "Unser Ziel ist es, mit den 303 Beobachtungen ein Modell zu generieren, welches neue Beobachtungen (bzw. Personen) klassifizieren und somit bestimmen kann, ob eine Herzerkrankung (HD) vorliegt oder nicht. Im Modell nutzen wir die oben beschriebenen Features um die Zielvariable (HD) vorherzusagen:\n",
    "* hd: Art der Herzerkrankung (hier: bin√§r)\n",
    "\n",
    "In einer Experten-Gruppe von Data Scientisten haben wir besprochen, welches Modell wir verwenden m√∂chten. Wir haben uns entschieden, Entscheidungb√§ume zur Klassifizierung von Herzerkrankungen zu benutzen, da diese einfach interpretierbar sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Datenaufbereitung (12 min) <a class=\"anchor\" name=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read data\n",
    "\n",
    "Bei jedem neuen Python-Projekt √ºberlegen wir uns, welche Python-Bibliotheken wir verwenden m√∂chten. Eine Python-Bibliothek ist ein wiederverwendbarer Codeblock, den wir in einem Programm bzw. Projekt einbinden k√∂nnen. Das Einbinden von solchen Codeblocks ist einiges schneller und zuverl√§ssiger, als den Code selber zu schreiben.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "In Python ist alles was hinter einem '#' steht, ein Kommentar um den Code zu beschreiben. </div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "# pandas: Bibliothek zum Lesen und Bearbeiten von Daten\n",
    "import pandas as pd\n",
    "# numpy: Bibliothek zum Berechnen von KPIs\n",
    "import numpy as np\n",
    "# plt: Bibliothek zum Plotten von Grafiken\n",
    "import matplotlib.pyplot as plt\n",
    "# DecisionTreeClassifier: Modellierungskit f√ºr Entscheidungsb√§ume\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# plot_tree: Funktion zum Plotten von Entscheidungsb√§umen\n",
    "from sklearn.tree import plot_tree\n",
    "# train_test_split: Funktion, um Testobjekte in Training- bzw. Testset zu splitten\n",
    "from sklearn.model_selection import train_test_split\n",
    "# cross_val_score: Funktion zur Kreuzvalidierung\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# confusion_matrix: Funktion zum Berechnen der Wahrheitsmatrix (Konfusionsmatrix)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# ConfusionMatrixDispla: Funktion zum Plotten der Konfusionsmatrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# accuracy_score: Funktion zum Berechnen der Accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>   In Python werden Daten mit Hilfe des '=' Operators in einer Variable gespeichert. Wenn wir beispielsweise die Zahl 5 in der Variable 'a' speichern m√∂chten, k√∂nnen wir das mit dem folgenden Code machen:\n",
    "<br><br>\n",
    "a = 5 \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(filepath_or_buffer, sep, encoding) erm√∂glicht es '.csv' Daten einzulesen\n",
    "# pd bezeichnet dabei die pandas-Bibliothek, mit der man Daten bearbeiten kann, der \".\" gibt an, dass wir eine Methode (read_csv) aus pd verwenden\n",
    "# Der Output wird in der Variable df als DataFrame-Objekt gespeichert.\n",
    "df = pd.read_csv(filepath_or_buffer='data/processed_cleveland_small.csv',\n",
    "                 sep=',',\n",
    "                 encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir die Variable 'df' aufrufen, wird sie angezeigt\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_2'></a>\n",
    "&#9989; **AUFGABE 2:**</b>\n",
    "Speichere die Daten in der Variable 'df_start'\n",
    "    \n",
    "-> L√∂sungen zu [Aufgabe 2](#l√∂sung_aufgabe_2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() zeigt, wie die ersten f√ºnf Zeilen von df_start aussehen\n",
    "df_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fehlende Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir den Spaltennamen in eckige Klammern schreiben, z.B. df_start['Spaltenname'], erhalten wir die Werte dieser Spalte\n",
    "df_start['ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte angezeigte Wert ist ein '?'. Wir wollen pr√ºfen, ob es noch mehr solche 'speziellen' Werte gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .unique() zeigt alle verschiedenen Elemente in der Spalte 'ca'\n",
    "df_start['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Wert '?' ist der einzige nicht-numerische Wert in der Spalte 'ca'. Bei solchen Werten m√ºssen wir vorsichtig sein. Es kann sich um einen Ausreisser oder einen fehlenden Wert handeln. Das Data Science Team nimmt deshalb Kontakt mit dem Autor des Datensatzes auf. Nach einigen Abkl√§rungen sind wir uns sicher, dass es fehlende Daten sind. Wir wissen jedoch noch nicht, wie oft solche fehlenden Daten vorkommen.\n",
    "\n",
    "Um zu sehen, wie oft dieser Wert vorkommt, filtern wir nach dem Wert '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Tabellenname['Spaltenname'] == 'zu pr√ºfender Text'] kann verwendet werden, um eine Tabelle nach einem spezifischen Spaltenwert zu filtern\n",
    "df_start[df_start['ca'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Wert '?' kommt nur sehr selten vor. Wir beschliessen, diese Beobachtungen aus dem Datensatz zu entfernen. Das heisst: Wir entfernen jede Beobachtung mit einem Fragezeichen. In realen Anwendungen werden oft raffiniertere Verfahren angewendet, welche die Information in den anderen Variablen solcher Beobachtungen nicht ignorieren. Besonders B√§ume k√∂nnen das sehr gut automatisch machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b>  Die wichtigsten Vergleichsoperatoren:\n",
    "    \n",
    "* ```==```: zu vergleichendes Element muss den gleichen Inhalt haben\n",
    "* ```!=```: zu vergleichendes Element darf nicht den gleichen Inhalt haben\n",
    "* ```>=```: zu vergleichende Zahl muss gleich oder gr√∂sser sein\n",
    "* ```<=```: zu vergleichende Zahl muss gleich oder kleiner sein\n",
    "     \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_3'></a>\n",
    "&#9989; **AUFGABE 3:**</b>\n",
    "Wir haben gesehen, dass nur 4 Testobjekte in der Spalte 'ca' ein '?' enthalten. Da die Abkl√§rungen ergeben haben, dass es fehlende Daten sind, und dieses Ph√§nomen nur sehr wenige Testobjekte betrifft, wollen wir diese Werte aus unserer 'df_start' Tabelle rausfiltern und die neue Tabelle unter 'df_no_missing' speichern.\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 3](#l√∂sung_aufgabe_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Mit diesem Code pr√ºfen wir, ob alle '?' entfernt worden sind.\n",
    "df_no_missing['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ausreisser\n",
    "\n",
    "Die Autoren des Datensatzes haben uns bei dem Austausch gesagt, dass es zu unerkl√§rbaren Werten beim Alter gekommen ist. Das heisst: bei dem folgenden Feature vermuten wir Ausreisser (Outliers):\n",
    "* age: Alter der Testobjekte\n",
    "\n",
    "Eine weitverbreitete M√∂glichkeit, um die Daten auf Ausreisser zu pr√ºfen, ist mithilfe von Visualisierungen wie etwa den Boxplots. Ein Boxplot ist eine grafische Darstellung statistischer Verteilungen, die den Median, Quartile und Ausreisser visualisiert, indem es die Daten in Boxen darstellt.\n",
    "\n",
    "![alt text for screen readers](./pictures/boxplot-new.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .boxplot(Spaltenname) zeigt einen Boxplot f√ºr ein bestimmtes Feature\n",
    "df_no_missing.boxplot('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass es im Feature ```age``` keine Ausreisser hat. Die Autoren des Datensatzes scheinen die Daten schon bereinigt zu haben. Falls Ausreisser vorkommen, sollte man diese entfernen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Daten formatieren\n",
    "Im n√§chsten Schritt erfolgt die Aufteilung der Daten in Features und die Zielvariable. Alle Merkmale werden in den DataFrame ```X``` aufgenommen, w√§hrend die Werte der Zielvariable in  ```y``` gespeichert werden.\n",
    "\n",
    "Hierbei repr√§sentiert ```X``` potenzielle Beobachtungen, also Daten von Personen, und ```y``` steht f√ºr die m√∂glichen Klassifizierungen (```0```=```keine Herzkrankheit```; ```1```=```hat Herzkrankheit```). Das √ºbergeordnete Ziel besteht darin, einen Entscheidungsbaum zu erstellen, der ```y``` m√∂glichst genau in Abh√§ngigkeit von ```X``` klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit der Funktion .copy() erstellen wir eine Kopie der Tabelle (um die Originaldaten df_no_missing nicht zu ver√§ndern)\n",
    "df_clean = df_no_missing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Features sollen in der Tabelle 'X' gespeichert werden\n",
    "# Die Funktion .drop('Spaltenname', axis=1) wird verwendet, um eine Spalte zu entfernen\n",
    "# Mit der Funktion .copy() erstellen wir eine Kopie der Tabelle\n",
    "X = df_clean.drop('hd', axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In diesem Schritt speichern wir die Zielvariable als 'y'\n",
    "y = df_clean['hd'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im n√§chsten Schritt erfolgt die Aufteilung unserer Daten in ein ```Trainingsset``` und ein ```Testset```:\n",
    "\n",
    "- ```Trainingsset```: Hierbei handelt es sich um Daten, die verwendet werden, um einen Entscheidungsbaum zu konstruieren und ihn anhand spezifischer Beobachtungen zu trainieren. Das Ziel ist es, dem Baum die charakteristischen Eigenschaften eines Datensatzes beizubringen.\n",
    "- ```Testset```: Dieses Datenset wird genutzt, um den Entscheidungsbaum zu testen. Es erm√∂glicht die √úberpr√ºfung, wie gut der Baum in der Lage ist, neue Beobachtungen zu klassifizieren und somit seine Genauigkeit zu bewerten.\n",
    "\n",
    "![alt text for screen readers](./pictures/train_test_split.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion train_test_split() teilt die Daten in ein Trainings- und in ein Testset\n",
    "# Standardm√§ssig sind im Testset 25% der Daten vorhanden und im Trainingsset 75%\n",
    "# Wir sehen, dass train_test_split(X, y) 4 Tabellen generiert (je eine X und y Tabelle f√ºr beide Sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Einfacher Entscheidungsbaum (10 min) <a class=\"anchor\" name=\"fourth-bullet\"></a>\n",
    "### 4.1 Einfacher Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt konstruieren/trainieren wir einen ```einfachen Entscheidungsbaum``` (ohne Optimierungen) abh√§ngig von unseren Beobachtungen im Trainingsset. Dieser Entscheidungsbaum erlaubt eine erste Klassifizierung von Objekten (z.B. Personen) hinsichtlich einer Herzkrankheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion DecisionTressClassifier() wird f√ºr die Konstruktion eines Entscheidungsbaumes verwendet. Das setzen des random state soll reproduzierabre Ergebnisse erzeugen.\n",
    "clf_dt_e = DecisionTreeClassifier(random_state=42)\n",
    "# .fit(X_train, y_train) weist dem Entscheidungsbaum ein Trainingsset (X_train und y_train) zu\n",
    "clf_dt_e.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualisierung: Mit dem folgenden Code k√∂nnen wir einen Entscheidungsbaum visualisieren/plotten\n",
    "# Hier wird die Gr√∂sse des Plots in Inch definiert (15 steht f√ºr die Breite und 7.5 steht f√ºr die H√∂he)\n",
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# Die Funktion plot_tree(decision_tree, class_names, feature_names) wird f√ºr die Visualisierung eines Entscheidungsbaumes verwendet\n",
    "# 'decision_tree' steht f√ºr den Entscheidungsbaum der visualisiert werden soll\n",
    "plot_tree(decision_tree=clf_dt_e,\n",
    "          # 'filled=True' f√ºhrt dazu, dass die Knoten mit Farben gef√ºllt werden\n",
    "          filled=True,\n",
    "          # 'class_names=[\"kein HD\", \"hat HD\"]' gibt die Klassen an, die in jedem Knoten unter 'class' stehen sollen\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          # 'feature_names=X.columns' muss mitgegeben werden, damit die Features im Plot korrekt bezeichnet werden\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herzlichen Gl√ºckwunsch! Wir haben unseren ersten einfachen Entscheidungsbaum konstruiert. Jetzt wollen wir sehen, wie gut dieser Entscheidungsbaum, welchen wir mit dem Trainingsset trainiert haben, Klassifizierungen im Testset vornehmen kann. Das bedeutet, wir wollen sehen, wie neue Personen klassifiziert werden, welche nicht f√ºr das Training verwendet worden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .predict(Tabellenname) wird verwendet, um die Klassifizierungen durchzuf√ºhren\n",
    "# Als Input muss dieser Funktion ein Tabellenname mitgegeben werden -> die Tabelle muss die Test-Features enthalten\n",
    "predictions = clf_dt_e.predict(X_test)\n",
    "# Der Output ist eine Liste mit den Klassifizierungen (0=keine HD; 1=hat HD)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem n√§chsten Schritt wollen wir pr√ºfen, ob diese Klassifizierungen richtig oder falsch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion confusion_matrix(y_true, y_pred, labels) bietet eine M√∂glichkeit zur Pr√ºfung der Klassifizierung\n",
    "# 'y_true' -> Liste der korrekten Klassifizierungen\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      # 'y_pred' -> Liste der vogenommenen Klassifizierungen\n",
    "                      y_pred=predictions,\n",
    "                      # 'labels' -> Klassen von clf_dt mitgeben\n",
    "                      labels=clf_dt_e.classes_)\n",
    "\n",
    "# Die Funktion ConfusionMatrixDisplay(confusion_matrix, display_labels) dient zur Visualisierung der Confusion-Matrix 'cm'\n",
    "# 'confusion_matrix' -> Confusion-Matrix die visualisiert werden soll\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              # 'display_labels' -> welche Labels sollen auf der Visualisierung dargestellt werden\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "# Die Funktion .plot() erstellt die Visualisierung\n",
    "disp.plot()\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die oben abgebildete Grafik zeigt eine ```Confusion-Matrix```. Sie wird wie folgt gelesen:\n",
    "- ```31```: Haben keine Herzkrankheit -> Diese 31 haben wir korrekt klassifiziert (True Negative TN) <br>\n",
    "- ```12```: Haben keine Herzkrankheit -> Diese 12 haben wir falsch klassifiziert (False Negative FN) <br>\n",
    "- ```25```: Haben eine Herzkrankheit -> Diese 25 haben wir korrekt klassifiziert (True Positive TP) <br>\n",
    "- ``` 7```: Haben eine Herzkrankheit -> Diese 7 haben wir falsch klassifiziert (False Positive FP)\n",
    "\n",
    "Wie gut ein Entscheidungsbaum ist, definieren wir anhand der ```Accuracy```, welche mit Hilfe der ```Confusion-Matrix``` berechnet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "<br>\n",
    "<br>... bei unserem einfachen Entscheidungsbaum haben wir z.B. folgende accuracy:\n",
    "<br> \n",
    "<br>Accuracy = (25 + 31) / (25 + 31 + 7 + 12) = 0.75\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion accuracy_score(y_true, y_pred) zeigt die berechnete Accuracy\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Optimierter Entscheidungsbaum (10 min) <a class=\"anchor\" name=\"fifth-bullet\"></a>\n",
    "### 5.1 Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/ccp.png \"Pruning\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bisher einen ```einfachen Entscheidungsbaum``` konstruiert. Zusammen mit dem Data Science Team besprechen wir, ob dieser Entscheidungsbaum ausreichend ist. Jemand aus dem Team hat einen Zweifel: der Entscheidungsbaum k√∂nnte auf die Trainigsset √ºberangepasst (overfitting) sein. √úberanpassung/Overfitting ist ein bekanntes Ph√§nomen. Es bedeutet, dass die Klassifizierung von Beobachtungen aus unserem Trainigsset sehr gut funktioniert, aber weniger gut f√ºr die Klassifizierung von neuen Beobachtungen. Der Entscheidungsbaum ist also zu sehr an die Trainingsdaten angepasst (√ºberangepasst).\n",
    "\n",
    "Dieses Problem k√∂nnen wir l√∂sen, indem wir die Konstruktion des Entscheidungsbaumes vereinfachen. Dazu verwenden wir verschiedene Parameter (z. B. ```max_ Depth``` oder ```min_samples```) um den Entscheidungsbaum zu optimieren. Das f√ºhrt dazu, dass der Entscheidungsbaum weniger Bl√§tter hat und dadurch einfacher und weniger an die Trainingsdaten angepasst ist. Diesen Prozess nennt man ```Pruning```. Das Ziel ist es, mithilfe des ```Pruning``` die ```Accuracy``` f√ºr neue Beobachtungen zu verbessern.\n",
    "\n",
    "```Cost Complexity Pruning``` ist eine spezifische Methode, um einen kleineren Entscheidungsbaum zu finden, der bessere Ergebnisse bei neuen Beobachtungen liefert. Wir schauen, ob kleinere Teil-Entscheidungsb√§ume (Baum mit 38 Bl√§ttern, Baum mit 37 Bl√§ttern, etc.) bessere Ergebnisse liefern als gr√∂ssere. Damit kleinere B√§ume mit gr√∂sseren B√§umen verglichen werden k√∂nnen, verwenden wir den Parameter ```alpha``` als ein Strafterm/Penalty, der das Ergebnis von kleineren B√§umen verbessert (√úberanpassung vs. Genauigkeit im Testdatenset).\n",
    "\n",
    "Eine genauere Anleitung zum ```Cost Complexity Pruning``` findet ihr [hier](#anhang_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "&#128712; **INFO:**</b> \n",
    "\n",
    "Die Werte von ```alpha``` sind wie folgt zu interpretieren:\n",
    "- ``` 0```: Der Entscheidungsbaum ist nicht geprunt. Er hat die maximale Gr√∂sse und entspricht dem in Kapitel 4 konstruierten einfachen Entscheidungsbaum.\n",
    "- ```>0```: Je gr√∂sser ```alpha``` desto einfacher ist der Entscheidungsbaum. Das heisst, der Entscheidungsbaum wir mit steigendem ```alpha``` weniger Bl√§tter haben.\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .cost_complexity_pruning_path(X_train, y_train) ist ein Algorithmus um m√∂glichst optimale Werte f√ºr alpha zu finden.\n",
    "path = clf_dt_e.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir w√§hlen einen Wert aus der Liste und konstruieren einen Entscheidungsbaum mit 'alpha' = 0.0077381\n",
    "value_alpha = 0.0077381\n",
    "\n",
    "# Definition des Entscheidungsbaums\n",
    "clf_dt_new = DecisionTreeClassifier(random_state=42,\n",
    "                                    ccp_alpha=value_alpha)\n",
    "clf_dt_new.fit(X_train, y_train)\n",
    "\n",
    "# Visualisierung des Entscheidungsbaums\n",
    "plot_tree(decision_tree=clf_dt_new,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_4'></a>\n",
    "&#9989; **AUFGABE 4:**</b>\n",
    "\n",
    "Konstruiere und visualisiere drei verschiedene Entscheidungsb√§ume mit verschiedenen ```alpha``` Werten. F√ºr die Konstruktion k√∂nnen wir den obigen Code verwenden und kopieren.\n",
    "    \n",
    "Wir sollten sicherstellen, dass die Entscheidungsb√§ume in den folgenden Variablen abgespiechert werden (ersetze ```clf_dt_new``` mit ```clf_dt_1```):\n",
    "- clf_dt_1\n",
    "- clf_dt_2\n",
    "- clf_dt_3\n",
    "\n",
    "-> L√∂sungen zu [Aufgabe 4](#l√∂sung_aufgabe_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√ºr den konstruierten Entscheidungsbaum 'clf_dt_new' wollen wir die Confusion-Matrix plotten, um die Performance zu pr√ºfen\n",
    "# Klassifizierungen\n",
    "predictions = clf_dt_new.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_new.classes_)\n",
    "\n",
    "# Visualisierung der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='aufgabe_5'></a>\n",
    "&#9989; **AUFGABE 5:**</b>\n",
    "\n",
    "Visualisiere die Confusion-Matrix f√ºr die in Aufgabe 4 konstruierten Entscheidungsb√§ume. F√ºr die Visualisierungen k√∂nnen wir den obigen Code verwenden und kopieren.\n",
    "<br>\n",
    "<br>-> L√∂sungen zu [Aufgabe 5](#l√∂sung_aufgabe_5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene L√∂sung:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben gesehen, dass je nach ```alpha``` die Ergebnisse schlechter oder besser werden. Wir √ºberlegen uns in unserem Team, wie wir auf eine einfache Art dasjenige ```alpha``` finden, bei welchem die Ergebnisse am besten sind.\n",
    "\n",
    "Da wir das nicht von Hand pr√ºfen m√∂chten, schreiben wir einen Code der Folgendes f√ºr uns erledigt:\n",
    "1. Einen Entscheidungsbaum pro ```alpha``` Wert konstruieren\n",
    "2. Pro Entscheidungsbaum die ```Accuracy``` f√ºr das Testset und das Trainingsset berechnen\n",
    "3. Die ```Accuracy``` f√ºr jeden Entscheidungsbaum in Abh√§ngigkeit von ```alpha``` visualisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Komplexe Code-Zelle:</b> \n",
    "\n",
    "Die nachfolgende Code-Zelle muss nur ausgef√ºhrt werden. Das Nachvollziehen der Funktionsweise ist nicht Teil dieser Einf√ºhrung.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit [:-1] entfernen wir den gr√∂ssten 'alpha' Wert (das gr√∂sste 'alpha' hat keine Bl√§tter)\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "clf_dts = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    clf_dts.append(clf_dt)\n",
    "    \n",
    "# Mit dem untenstehenden Code stellen wir 'Accuracy' in Abh√§ngigkeit zu 'alpha' dar (f√ºr Testdaten und Trainingsdaten)\n",
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Visualisierung finden wir die n√∂tigen Informationen, welche wir brauchen, um das beste ```alpha``` zu finden. Da wir m√∂glichst einen generalisierbaren Entscheidungsbaum erstellen m√∂chten, interessiert uns vor allem die orange Linie (```Testdaten```).\n",
    "\n",
    "Bei der Auswahl des besten ```alpha``` achten wir auf die folgenden zwei Punkte:\n",
    "1. Die ```Accuracy``` von ```test``` soll m√∂glichst gross sein\n",
    "2. Die ```Accuracy``` von ```train``` soll m√∂glichst gross sein\n",
    "\n",
    "Unter Ber√ºcksichtigung der aufgef√ºhrten Punkte ist das optimale ```alpha``` also der sechstletzte Punkt auf der ```test``` Linie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um den sechstletzten Punkt zu finden rufen wir nochmals die Liste mit den 'alpha' Werten auf\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir definieren und speichern das optimale 'alpha'\n",
    "alpha_opt = 0.01081731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Entscheidungsbaums\n",
    "clf_dt_pruned = DecisionTreeClassifier(random_state=42,\n",
    "                                       ccp_alpha=alpha_opt)\n",
    "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung des Entscheidungsbaums\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plot_tree(clf_dt_pruned,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accuracy' des neuen Entscheidungsbaumes\n",
    "predictions_new = clf_dt_pruned.predict(X_test)\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten die folgenden ```Accuracy-Werte```:\n",
    "* einfacher Entscheidungsbaum = ```0.746``` (75%)\n",
    "* optimierter Entscheidungsbaum =  ```0.786``` (79%)\n",
    "\n",
    "Wenn wir diese beiden Werte vergleichen, sehen wir, dass wir durch die Optimierung einen Entscheidungsbaum erhalten haben, welcher besser mit neuen Beobachtungen umgehen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Abschluss (5 min) <a class=\"anchor\" name=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was haben wir gelernt:\n",
    "* Was sind Entscheidungsb√§ume?\n",
    "* Wie lesen wir Entscheidungsb√§ume?\n",
    "* Wie bereiten wir Daten auf (fehlende Daten & Ausreisser)?\n",
    "* Arbeiten mit Trainings- und Testset\n",
    "* Erstellen von einfachen Entscheidungsb√§umen\n",
    "* Optimieren von einfachen Entscheidungsb√§umen\n",
    "* Accuracy und Confusion-Matrix\n",
    "\n",
    "Was muss man beachten, wenn man Modelle integrieren will:\n",
    "* Generalisierung\n",
    "* Software-Engineering-Skills um Modelle in Applikationen einzubinden\n",
    "* Antwortzeiten\n",
    "* Monitoren der Vorhersagequalit√§t\n",
    "* Zusammenarbeit von mehreren Rollen (Data-Engineer, Data-Scientist, Software-Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Anhang <a class=\"anchor\" name=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='anhang_1'></a>\n",
    "### Anhang 1: Anleitung Cross Complexity Pruning\n",
    "\n",
    "Der Algorithmus zur Kostenkomplexit√§tsbeschneidung folgt in der Regel diesen Schritten:\n",
    "\n",
    "1. Erstelle einen anf√§nglichen Entscheidungsbaum mit einem Trainingsdatensatz unter Ber√ºcksichtigung aller verf√ºgbaren Attribute und Merkmale.\n",
    "2. Bewerte die Klassifikationsleistung des Entscheidungsbaums anhand eines separaten Validierungsdatensatzes.\n",
    "3. Berechne f√ºr jeden internen Knoten des Entscheidungsbaums seine potenziellen Kosten in Bezug auf die fehlerhafte Klassifizierung oder anderer Metriken.\n",
    "4. Weise jedem internen Knoten eine Kostenkomplexit√§tswertung zu, die in der Regel als Summe seiner Kosten f√ºr fehlerhafte Klassifizierung und eines Strafterms berechnet wird, der proportional zur Anzahl der absteigenden Blattknoten ist.\n",
    "5. Beginnend beim Wurzelknoten beschneide iterativ den Knoten mit der niedrigsten Kostenkomplexit√§tswertung und erstelle eine Reihe von kleineren Entscheidungsb√§umen.\n",
    "6. Bewerte die Klassifikationsleistung jedes beschnittenen Entscheidungsbaums anhand des Validierungsdatensatzes.\n",
    "7. W√§hle den beschnittenen Baum mit der besten Leistung aus, die oft anhand der Genauigkeit oder einer anderen geeigneten Metrik gemessen wird.\n",
    "8. Optional kann man den ausgew√§hlten Baum weiter beschneiden, indem man den Komplexit√§tsparameter Œ± optimiert und die Schritte 5-7 wiederholt.\n",
    "9. Der endg√ºltige beschnittene Entscheidungsbaum wird erzielt, wenn durch zus√§tzliches Beschneiden keine weiteren Verbesserungen der Leistung erzielt werden k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 L√∂sungen <a class=\"anchor\" name=\"eight-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_1'></a>\n",
    "### L√∂sung Aufgabe 1\n",
    "\n",
    "Klassen:\n",
    "- Datenobjekt 1 = 'Has Insurance'\n",
    "- Datenobjekt 2 = 'Has Insurance' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/L√∂sung_mit_Pfaden.png \"L√∂sung\").\n",
    "\n",
    "-> Zur√ºck zu [Aufgabe 1](#aufgabe_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_2'></a>\n",
    "### L√∂sung Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 2](#aufgabe_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_3'></a>\n",
    "### L√∂sung Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing = df_start[df_start['ca'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 3](#aufgabe_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_4'></a>\n",
    "### L√∂sung  Aufgabe 4\n",
    "\n",
    "Die folgenden Code-Zellen bilden eine m√∂gliche L√∂sung zu Aufgabe 4 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# Wir w√§hlen einen Wert aus der Liste und konstruieren einen Entscheidungsbaum mit 'alpha' = 0.0000000000001\n",
    "value_alpha = 0.0000000000001\n",
    "\n",
    "# Definition des Entscheidungsbaums\n",
    "clf_dt_1 = DecisionTreeClassifier(random_state=42,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_1.fit(X_train, y_train)\n",
    "\n",
    "# Visualisierung des Entscheidungsbaums\n",
    "plot_tree(decision_tree=clf_dt_1,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# Wir w√§hlen einen Wert aus der Liste und konstruieren einen Entscheidungsbaum mit 'alpha' = 0.01425422\n",
    "value_alpha = 0.01425422\n",
    "\n",
    "# Definition des Entscheidungsbaums\n",
    "clf_dt_2 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_2.fit(X_train, y_train)\n",
    "\n",
    "# Visualisierung des Entscheidungsbaums\n",
    "plot_tree(decision_tree=clf_dt_2,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# Wir w√§hlen einen Wert aus der Liste und konstruieren einen Entscheidungsbaum mit 'alpha' = 0.2\n",
    "value_alpha = 0.2\n",
    "\n",
    "# Definition des Entscheidungsbaums\n",
    "clf_dt_3 = DecisionTreeClassifier(random_state=42,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_3.fit(X_train, y_train)\n",
    "\n",
    "# Visualisierung des Entscheidungsbaums\n",
    "plot_tree(decision_tree=clf_dt_3,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 4](#aufgabe_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='l√∂sung_aufgabe_5'></a>\n",
    "### L√∂sung  Aufgabe 5\n",
    "Die folgenden Code-Zellen bilden eine m√∂gliche L√∂sung zu Aufgabe 5 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifizierungen\n",
    "predictions = clf_dt_1.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_1.classes_)\n",
    "\n",
    "# Visualisierung der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifizierungen\n",
    "predictions = clf_dt_2.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_2.classes_)\n",
    "\n",
    "# Visualisierung der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifizierungen\n",
    "predictions = clf_dt_3.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_3.classes_)\n",
    "\n",
    "# Visualisierung der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# Die Funktion plt.show() zeigt den Plot an\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Zur√ºck zu [Aufgabe 5](#aufgabe_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Quellen <a class=\"anchor\" name=\"nineth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#169; Quellen:\n",
    "&#128190; **Daten:** https://archive.ics.uci.edu/dataset/45/heart+disease \n",
    "<br>\n",
    "&#128252;  **Video:** https://youtu.be/q90UDEgYqeI?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB\n",
    "\n",
    "### &#128161; Weitere Informationen:\n",
    "\n",
    "``` Decision Trees: ``` &nbsp; https://www.youtube.com/watch?v=7VeUPuFGJHk&t=0s\n",
    "<br>\n",
    "``` Cross Validation: ``` &nbsp; https://www.youtube.com/watch?v=fSytzGwwBVw&t=0s\n",
    "<br>\n",
    "``` Confusion Matrix: ``` &nbsp; https://www.youtube.com/watch?v=Kdsp6soqA7o&t=0s\n",
    "<br>\n",
    "``` Cost-Complexity Pruning: ``` &nbsp; https://www.youtube.com/watch?v=D0efHEJsfHo&t=0s\n",
    "<br>\n",
    "``` Bias and Variance and Overfitting: ``` &nbsp; https://www.youtube.com/watch?v=EuBBz3bI-aA&t=0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
